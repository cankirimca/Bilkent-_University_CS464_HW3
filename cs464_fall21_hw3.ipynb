{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDSS2c_hXISc"
   },
   "source": [
    "**<h1><center>CS 464</center></h1>**\n",
    "**<h1><center>Introduction to Machine Learning</center></h1>**\n",
    "**<h1><center>Fall 2021</center></h1>**\n",
    "**<h1><center>Homework 3</center></h1>**\n",
    "<h4><center>Due: Jan 02, 2022 17:00 (GMT+3)</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5qurNR3XkKT"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "    This homework contains both written and programming questions about neural networks. You should implement programming questions on this notebook. Your plots should also be produced in this notebook. Each programming question has its own cell for your answer. You can implement your code directly in these cells, or you can call required functions which are defined in a different location for the given question.\n",
    "    </li>\n",
    "    <li>\n",
    "    For questions that you need to plot, your plot results have to be included in the cell output. For written questions, you may provide them either as comments in code cells or as seperate text cells. \n",
    "    </li>\n",
    "    <li>\n",
    "    You are <b>NOT ALLOWED</b> to use different libraries than given libraries in the code segments of this homework except for libraries inclueded in Python Standard Library (https://docs.python.org/3/library/).\n",
    "    </li>\n",
    "    <li>\n",
    "    You are <b>NOT ALLOWED</b> to use a different deep learning framework than PyTorch.\n",
    "    </li>\n",
    "    <li>\n",
    "    While submitting the homework file, please package notebook(\".ipynb\") and model (\".pth\") files as a gzipped TAR file or a ZIP file with the name cs464_hw3_section#_Firstname_Lastname. Please do not use any Turkish letters for any of your files including code files and model files. Upload your homework to Moodle.\n",
    "    </li>\n",
    "    <li>\n",
    "    This is an individual assignment for each student. That is, you are NOT allowed to share your work with your classmates.</li>\n",
    "    <li> \n",
    "    If you do not follow the submission routes, deadlines and specifications, it will lead to a significant grade deduction.\n",
    "    </li>\n",
    "    <li> \n",
    "    If you have any questions, please contact \"hakansivuk@gmail.com\".\n",
    "    </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d7BOVodYiGe"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPlCx2GsYnHS"
   },
   "source": [
    "This homewrok is prepeared by using Google CoLab which already has required libraries. However, if you are using your own local Jupyter or any other Python notebook editor, you may use both anaconda or pip to install PyTorch to your own computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM4dpplWZBGS"
   },
   "source": [
    "### Anaconda Installation\n",
    "\n",
    "<ul>\n",
    "    <li>Download anaconda from https://www.anaconda.com/download</li>\n",
    "    <li>Follow the instructions provided in https://conda.io/docs/user-guide/install/index.html#regular-installation</li>\n",
    "</ul>\n",
    "\n",
    "#### Creation of Virtual Environment\n",
    "\n",
    "<ul>\n",
    "    <li>Create python3.7 virtual environment for your hw3 using follow command from the command line<br>\n",
    "        <i>> conda create -n HW3 python=3.7 anaconda</i></li>\n",
    "    <li>Activate your virtual environment<br>\n",
    "        <i>> source activate HW3</i></li>\n",
    "    <li>To install auxiliary libraries, replace the \"package_name\" in the following command and run it in activated \"hw3\" environment <br>\n",
    "        <i>> pip install \"package_name\"<i></li>\n",
    "     <li>When you create your virtual environment with \"anaconda\" metapackage, jupyter notebook should be installed. Try:<br>\n",
    "         <i>> jupyter notebook</i>\n",
    "</ul>\n",
    "\n",
    "\n",
    "#### Pytorch Installation with Anaconda\n",
    "\n",
    "You should install PyTorch to your virtual environment which is created for the hw3. Therefore, you should activate your homework virtual environment before to start PyTorch installation.\n",
    "<li>> source activate HW3</li>\n",
    "\n",
    "After you have activated the virtual environment, then use one of the following commands to install pytorch for CPU for your system. See https://pytorch.org/ for help.\n",
    "<ul>\n",
    "<li>For MacOS:<br>\n",
    "    <i>> conda install pytorch torchvision -c pytorch</i>\n",
    "</li>\n",
    "<li>For Linux:<br>\n",
    "    <i>> conda install pytorch-cpu torchvision-cpu -c pytorch</i>\n",
    "</li>\n",
    "<li>For Windows:<br>\n",
    "    <i>> conda install pytorch-cpu torchvision-cpu -c pytorch</i><br>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVlcWIXEZZGO"
   },
   "source": [
    "###Pip3 Installation\n",
    "<ul>\n",
    "    <li>Download pip3 from https://pip.pypa.io/en/stable/installing/</li>\n",
    "    <li>If you are using Windows, you may need to add Python to your enviroment variables. You may use the following tutorial to install Python and pip.\n",
    "    https://phoenixnap.com/kb/how-to-install-python-3-windows</li>\n",
    "</ul>\n",
    "\n",
    "#### PyTorch Installation with Pip\n",
    "<ul>\n",
    "<li>For MacOS:<br>\n",
    "    <i>> pip3 install torch torchvision</i>\n",
    "</li>\n",
    "<li>For Linux:<br>\n",
    "    <i>> pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html</i>\n",
    "</li>\n",
    "<li>For Windows:<br>\n",
    "    <i>> pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html</i><br>\n",
    "</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0CsUtpmZmBk"
   },
   "source": [
    "##Question 1 [12 pts.]\n",
    "\n",
    "Answer the given questions with **at most a sentence**.\n",
    "\n",
    "  >a) Why do people use validation data?<br>\n",
    "          Answer) Results on the validation data gives a sense of model's accuracy while tuning the hyperparameters\n",
    "\n",
    "  >b) What is the difference between mean squared error and mean absolute error?  <br>\n",
    "          Answer) Large errors have more impact to MSE compared to MAE, therefore MSE is more sensitive to the magnitude of the error.\n",
    "\n",
    "  >c) What is the main problem of using sigmoid as activation function in an artificial neural network (ANN)?<br>\n",
    "          Answer) As the output of the function becomes stable, gradient will become very small and the network will not learn,\n",
    "          which is called the 'vanishing gradient problem'.\n",
    "\n",
    ">d) What does it mean to overfit your data model?<br>\n",
    "           Answer) Overfitting means that the model learns every feature of the data, even the noises, so that it perfectly fits the   training data and will not perform well on unseen data.\n",
    "\n",
    "  >e) Your input image size is 3x64x64. If you apply 3x3 convolution with input_channel=3, output_channel=6, padding=0, stride=2, what would be the size of the output?<br>\n",
    "          Answer) (64 - 2)/2 = 31, the output is of size 6x31x31\n",
    "\n",
    "  >f) In the previous question, how many trainable parameters are there? (you should also consider bias terms in addition to weights)<br>\n",
    "          Answer) We have (3x3x3x6) + (1x6) = 168 parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnAVhRr4eTPo"
   },
   "source": [
    "##Question 2 [88 pts.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnaXgIskP6iY"
   },
   "source": [
    "Computer vision (CV) is the field of study that deals with how computers can gain high-level understanding from digital images or videos. Your task for this question is to classify scenes according to their contexts by using simple machine learning algorithms developed for CV problems on scene images.\n",
    "\n",
    "Your dataset consist of scene images from 4 contexts. Images of each context is stored under separate folders in the compressed file given to you.  The dataset has been processed in such a way that each class has approximately 2500 samples.\n",
    "\n",
    "Download the dataset from the following link:\n",
    "<br>\n",
    "https://drive.google.com/file/d/1l51t3aTY7B131fwq92ACI_b_D5Idq5In/view?usp=sharing\n",
    "<br>\n",
    "\n",
    "Libraries that are required in this question is given in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Z37KSYkSXHtz"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "# To Read Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# To Interpret results & obtain plots\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You could add your own libraries form Python Standard Library in this cell. Any other external libraries are not allowed.\n",
    "import os\n",
    "import math\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda\" \n",
    "else:  \n",
    "    dev = \"cpu\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kkd-WIVwTQsn"
   },
   "source": [
    "### Data Loader [6 pts.]\n",
    "\n",
    "An important part of such a task is to implement your own data loader. In this homework, a partial loader is provided to you. This loader is going to be based on a base class named \"Dataset\", provided in PyTorch library. You need to complete the code below to create your custom \"SceneDataset\" class which will be able to load your dataset. Implement the functions whose proptotypes are given. Follow the TODO notes below. You have to divide the files into three sets as <b>train (70%)</b>, \n",
    "<b>validation (10%)</b> and **test (20%)** sets.  These non-overlapping splits, which are subsets of SceneDataset, should be retrieved using the \"get_dataset\" function.\n",
    "\n",
    "Hint: The dataset is not normalized and your results will heavily depend on your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "x9fac_LpYdXE"
   },
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "    # TODO:\n",
    "    # Define constructor for SceneDataset class\n",
    "    # HINT: You can pass processed data samples and their ground truth values as parameters \n",
    "    def __init__(self, data, labels): #**kwargs): # you are free to change parameters\n",
    "        self.data = torch.tensor(data, dtype=torch.float, device=dev)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float, device=dev)\n",
    "        \n",
    "    '''This function should return sample count in the dataset'''\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    '''This function should return a single sample and its ground truth value from the dataset corresponding to index parameter '''\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "vE3b0p2IWrdo"
   },
   "outputs": [],
   "source": [
    "def get_dataset(root):\n",
    "    # TODO: \n",
    "    # Normalize datasets\n",
    "    images = []\n",
    "    labels = []\n",
    "    label = 0\n",
    "    for root, dirs, files in os.walk(root):\n",
    "        for dir in dirs:\n",
    "            directory = \"{r}/{d}\".format(r=root, d = dir) \n",
    "            for root2, dirs2, files2 in os.walk(directory):\n",
    "                for filename in files2:\n",
    "                    path = \"{r}/{f}/{n}\".format(r=root, f=dir, n=filename)\n",
    "                    image = Image.open(open(path, 'rb'))\n",
    "                    np_image = np.array(image)/255\n",
    "                    images.append(np.transpose(np_image))\n",
    "                    gt = [0,0,0,0]\n",
    "                    gt[label] = 1\n",
    "                    labels.append(gt)\n",
    "            label += 1        \n",
    "    images = np.array(images, dtype='float64')\n",
    "    labels = np.array(labels, dtype='float64') \n",
    "    train_and_val_dataset_x, test_dataset_x, train_and_val_dataset_y, test_dataset_y = train_test_split(images, labels, test_size=0.2, random_state=1)   \n",
    "    train_dataset_x, val_dataset_x, train_dataset_y, val_dataset_y = train_test_split(train_and_val_dataset_x, train_and_val_dataset_y, test_size=0.125, random_state=1)\n",
    "    train_dataset = SceneDataset(train_dataset_x, train_dataset_y)\n",
    "    test_dataset = SceneDataset(test_dataset_x, test_dataset_y)\n",
    "    val_dataset = SceneDataset(val_dataset_x, val_dataset_y)\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFVQay-2Z7Ix"
   },
   "source": [
    "###Model Implementation [7 pts]\n",
    "\n",
    "Now implement your CNN. ConvNet class will represent your convolutional neural network. Implement 3 layers of convolution: \n",
    "<ul>\n",
    "    <li>(1) 4 filters with size of 3 x 3 with stride 1 and padding 1, (2) ReLU </li>\n",
    "    <li>(3) 8 filters with size of 3 x 3 with stride 1 and padding 1, (4) ReLU and (5) MaxPool 2 x 2 </li>\n",
    "    <li>(6) 16 filters with size of 3 x 3 with stride 1 and padding 1, (7) ReLU and (8) MaxPool 2 x 2 </li> \n",
    "</ul>\n",
    "\n",
    "As the classifier layer, you need to add only one linear layer at the end of the network. You need to choose the appropriate input and output neuron sizes and the activation function for the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lNnoeEy-aGA3"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''Define your neural network'''\n",
    "    def __init__(self, **kwargs): # you can add any additional parameters you want \n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3, stride=1, padding=1)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.classifier = nn.Linear(7744, 4)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "     \n",
    "    def forward(self, x): # you can add any additional parameters you want\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.mp(F.relu(self.conv2(x)))\n",
    "        x = self.mp(F.relu(self.conv3(x)))\n",
    "        flat = self.flatten(x)\n",
    "        return F.softmax(self.classifier(flat), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4HT9fvm_jgX"
   },
   "source": [
    "###Stochastic Gradient Descent [25 pts.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJO7J4sf7YGZ"
   },
   "source": [
    "####Training with SGD [15 pts.]\n",
    "\n",
    "Train your model up to 300 epochs with properly processed inputs, i.e. call your \"get_dataset\" function. Use SGD as your optimizer. Tune your learning rate, weight decay. Do not add additional parameters to SGD. Save your best model as \"best_cnn_sgd.pth\". The best model should be selected based on validation dataset. You could use any measurement and/or metric to decide on the best model. However, you must explain your reasoning in your choice.\n",
    "\n",
    "During training, you need to plot two figures:\n",
    "1. training loss and validation loss vs. epoch\n",
    "2. training accuracy and validation accuracy vs. epoch <br>\n",
    "\n",
    "Name your axes and plots properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "S4VU9L1jCNCC"
   },
   "outputs": [],
   "source": [
    "#get the dataset\n",
    "train_dataset, val_dataset, test_dataset = get_dataset(\"data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) Training: loss: 1.3861266352913597 , accuracy: 0.24942857142857142\n",
      "Validation: loss: 1.3859402239322662 , accuracy: 0.246\n",
      "New min loss: 1.3859402239322662\n",
      "2 ) Training: loss: 1.3855807087638161 , accuracy: 0.3667142857142857\n",
      "Validation: loss: 1.3852751553058624 , accuracy: 0.39\n",
      "New min loss: 1.3852751553058624\n",
      "3 ) Training: loss: 1.384870836951516 , accuracy: 0.3167142857142857\n",
      "Validation: loss: 1.3843646347522736 , accuracy: 0.255\n",
      "New min loss: 1.3843646347522736\n",
      "4 ) Training: loss: 1.3837752190503207 , accuracy: 0.2612857142857143\n",
      "Validation: loss: 1.3829139322042465 , accuracy: 0.253\n",
      "New min loss: 1.3829139322042465\n",
      "5 ) Training: loss: 1.3818739956075494 , accuracy: 0.262\n",
      "Validation: loss: 1.380261406302452 , accuracy: 0.259\n",
      "New min loss: 1.380261406302452\n",
      "6 ) Training: loss: 1.3780014103109186 , accuracy: 0.2792857142857143\n",
      "Validation: loss: 1.3743769079446793 , accuracy: 0.283\n",
      "New min loss: 1.3743769079446793\n",
      "7 ) Training: loss: 1.368502502007918 , accuracy: 0.32957142857142857\n",
      "Validation: loss: 1.3588096648454666 , accuracy: 0.352\n",
      "New min loss: 1.3588096648454666\n",
      "8 ) Training: loss: 1.342043662071228 , accuracy: 0.40785714285714286\n",
      "Validation: loss: 1.3157225400209427 , accuracy: 0.466\n",
      "New min loss: 1.3157225400209427\n",
      "9 ) Training: loss: 1.2801402785561302 , accuracy: 0.534\n",
      "Validation: loss: 1.2344026118516922 , accuracy: 0.578\n",
      "New min loss: 1.2344026118516922\n",
      "10 ) Training: loss: 1.201091970096935 , accuracy: 0.5852857142857143\n",
      "Validation: loss: 1.1696104258298874 , accuracy: 0.591\n",
      "New min loss: 1.1696104258298874\n",
      "11 ) Training: loss: 1.1579477656971324 , accuracy: 0.5915714285714285\n",
      "Validation: loss: 1.1439208090305328 , accuracy: 0.595\n",
      "New min loss: 1.1439208090305328\n",
      "12 ) Training: loss: 1.1388477997346358 , accuracy: 0.5951428571428572\n",
      "Validation: loss: 1.129913255572319 , accuracy: 0.61\n",
      "New min loss: 1.129913255572319\n",
      "13 ) Training: loss: 1.126944643800909 , accuracy: 0.6084285714285714\n",
      "Validation: loss: 1.1208053827285767 , accuracy: 0.625\n",
      "New min loss: 1.1208053827285767\n",
      "14 ) Training: loss: 1.1186032425273549 , accuracy: 0.6178571428571429\n",
      "Validation: loss: 1.114076554775238 , accuracy: 0.625\n",
      "New min loss: 1.114076554775238\n",
      "15 ) Training: loss: 1.1122554952448065 , accuracy: 0.6227142857142857\n",
      "Validation: loss: 1.1088155657052994 , accuracy: 0.63\n",
      "New min loss: 1.1088155657052994\n",
      "16 ) Training: loss: 1.1072031888094815 , accuracy: 0.6258571428571429\n",
      "Validation: loss: 1.1046863049268723 , accuracy: 0.633\n",
      "New min loss: 1.1046863049268723\n",
      "17 ) Training: loss: 1.1031334811990912 , accuracy: 0.6321428571428571\n",
      "Validation: loss: 1.1013641208410263 , accuracy: 0.638\n",
      "New min loss: 1.1013641208410263\n",
      "18 ) Training: loss: 1.099785293232311 , accuracy: 0.635\n",
      "Validation: loss: 1.0986872166395187 , accuracy: 0.639\n",
      "New min loss: 1.0986872166395187\n",
      "19 ) Training: loss: 1.096964506669478 , accuracy: 0.6407142857142857\n",
      "Validation: loss: 1.0965252369642258 , accuracy: 0.638\n",
      "New min loss: 1.0965252369642258\n",
      "20 ) Training: loss: 1.0945377479900014 , accuracy: 0.6418571428571429\n",
      "Validation: loss: 1.0946882516145706 , accuracy: 0.642\n",
      "New min loss: 1.0946882516145706\n",
      "21 ) Training: loss: 1.092403034730391 , accuracy: 0.6438571428571429\n",
      "Validation: loss: 1.0930808186531067 , accuracy: 0.642\n",
      "New min loss: 1.0930808186531067\n",
      "22 ) Training: loss: 1.0904804533178156 , accuracy: 0.6465714285714286\n",
      "Validation: loss: 1.091651290655136 , accuracy: 0.643\n",
      "New min loss: 1.091651290655136\n",
      "23 ) Training: loss: 1.0887173587625676 , accuracy: 0.6481428571428571\n",
      "Validation: loss: 1.090365707874298 , accuracy: 0.643\n",
      "New min loss: 1.090365707874298\n",
      "24 ) Training: loss: 1.0870877157558094 , accuracy: 0.649\n",
      "Validation: loss: 1.089179202914238 , accuracy: 0.644\n",
      "New min loss: 1.089179202914238\n",
      "25 ) Training: loss: 1.0855691649697043 , accuracy: 0.6502857142857142\n",
      "Validation: loss: 1.0880968868732452 , accuracy: 0.646\n",
      "New min loss: 1.0880968868732452\n",
      "26 ) Training: loss: 1.0841418331319637 , accuracy: 0.6512857142857142\n",
      "Validation: loss: 1.087117612361908 , accuracy: 0.646\n",
      "New min loss: 1.087117612361908\n",
      "27 ) Training: loss: 1.082799406485124 , accuracy: 0.6531428571428571\n",
      "Validation: loss: 1.0862208753824234 , accuracy: 0.645\n",
      "New min loss: 1.0862208753824234\n",
      "28 ) Training: loss: 1.081518613208424 , accuracy: 0.6547142857142857\n",
      "Validation: loss: 1.085388109087944 , accuracy: 0.644\n",
      "New min loss: 1.085388109087944\n",
      "29 ) Training: loss: 1.0803069591522216 , accuracy: 0.6554285714285715\n",
      "Validation: loss: 1.084574207663536 , accuracy: 0.646\n",
      "New min loss: 1.084574207663536\n",
      "30 ) Training: loss: 1.0791470007462935 , accuracy: 0.6577142857142857\n",
      "Validation: loss: 1.0837886184453964 , accuracy: 0.649\n",
      "New min loss: 1.0837886184453964\n",
      "31 ) Training: loss: 1.0780423760414124 , accuracy: 0.6578571428571428\n",
      "Validation: loss: 1.0830327719449997 , accuracy: 0.649\n",
      "New min loss: 1.0830327719449997\n",
      "32 ) Training: loss: 1.0769807425412266 , accuracy: 0.659\n",
      "Validation: loss: 1.0822512954473495 , accuracy: 0.649\n",
      "New min loss: 1.0822512954473495\n",
      "33 ) Training: loss: 1.0759666746312921 , accuracy: 0.6612857142857143\n",
      "Validation: loss: 1.0814802646636963 , accuracy: 0.65\n",
      "New min loss: 1.0814802646636963\n",
      "34 ) Training: loss: 1.074984482201663 , accuracy: 0.6622857142857143\n",
      "Validation: loss: 1.0806994289159775 , accuracy: 0.651\n",
      "New min loss: 1.0806994289159775\n",
      "35 ) Training: loss: 1.074034012447704 , accuracy: 0.664\n",
      "Validation: loss: 1.0799468159675598 , accuracy: 0.652\n",
      "New min loss: 1.0799468159675598\n",
      "36 ) Training: loss: 1.0731195189736107 , accuracy: 0.6655714285714286\n",
      "Validation: loss: 1.079194575548172 , accuracy: 0.653\n",
      "New min loss: 1.079194575548172\n",
      "37 ) Training: loss: 1.0722200588746504 , accuracy: 0.6662857142857143\n",
      "Validation: loss: 1.0784650892019272 , accuracy: 0.655\n",
      "New min loss: 1.0784650892019272\n",
      "38 ) Training: loss: 1.0713437481360002 , accuracy: 0.667\n",
      "Validation: loss: 1.0777629166841507 , accuracy: 0.657\n",
      "New min loss: 1.0777629166841507\n",
      "39 ) Training: loss: 1.0704870549115268 , accuracy: 0.6682857142857143\n",
      "Validation: loss: 1.0770719349384308 , accuracy: 0.658\n",
      "New min loss: 1.0770719349384308\n",
      "40 ) Training: loss: 1.0696417223323476 , accuracy: 0.6684285714285715\n",
      "Validation: loss: 1.0764042735099792 , accuracy: 0.658\n",
      "New min loss: 1.0764042735099792\n",
      "41 ) Training: loss: 1.0688131614164873 , accuracy: 0.6691428571428572\n",
      "Validation: loss: 1.0757452547550201 , accuracy: 0.658\n",
      "New min loss: 1.0757452547550201\n",
      "42 ) Training: loss: 1.067996812950481 , accuracy: 0.6697142857142857\n",
      "Validation: loss: 1.0751133561134338 , accuracy: 0.658\n",
      "New min loss: 1.0751133561134338\n",
      "43 ) Training: loss: 1.0671911109577525 , accuracy: 0.6695714285714286\n",
      "Validation: loss: 1.0744928568601608 , accuracy: 0.658\n",
      "New min loss: 1.0744928568601608\n",
      "44 ) Training: loss: 1.0663872231136668 , accuracy: 0.6717142857142857\n",
      "Validation: loss: 1.0738558322191238 , accuracy: 0.657\n",
      "New min loss: 1.0738558322191238\n",
      "45 ) Training: loss: 1.0655829407952049 , accuracy: 0.6728571428571428\n",
      "Validation: loss: 1.0732171833515167 , accuracy: 0.658\n",
      "New min loss: 1.0732171833515167\n",
      "46 ) Training: loss: 1.0647743300958112 , accuracy: 0.6735714285714286\n",
      "Validation: loss: 1.0725783556699753 , accuracy: 0.66\n",
      "New min loss: 1.0725783556699753\n",
      "47 ) Training: loss: 1.0639598694714634 , accuracy: 0.6747142857142857\n",
      "Validation: loss: 1.0719206482172012 , accuracy: 0.661\n",
      "New min loss: 1.0719206482172012\n",
      "48 ) Training: loss: 1.0631370750340547 , accuracy: 0.6757142857142857\n",
      "Validation: loss: 1.0712476819753647 , accuracy: 0.662\n",
      "New min loss: 1.0712476819753647\n",
      "49 ) Training: loss: 1.0623085964809764 , accuracy: 0.6775714285714286\n",
      "Validation: loss: 1.0705426633358002 , accuracy: 0.664\n",
      "New min loss: 1.0705426633358002\n",
      "50 ) Training: loss: 1.0614661715247415 , accuracy: 0.679\n",
      "Validation: loss: 1.0698365271091461 , accuracy: 0.666\n",
      "New min loss: 1.0698365271091461\n",
      "51 ) Training: loss: 1.060619675029408 , accuracy: 0.6798571428571428\n",
      "Validation: loss: 1.0691212266683578 , accuracy: 0.664\n",
      "New min loss: 1.0691212266683578\n",
      "52 ) Training: loss: 1.059773198041049 , accuracy: 0.68\n",
      "Validation: loss: 1.0683902651071548 , accuracy: 0.664\n",
      "New min loss: 1.0683902651071548\n",
      "53 ) Training: loss: 1.0589229399507696 , accuracy: 0.6807142857142857\n",
      "Validation: loss: 1.0676458925008774 , accuracy: 0.666\n",
      "New min loss: 1.0676458925008774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 ) Training: loss: 1.0580732280557805 , accuracy: 0.6807142857142857\n",
      "Validation: loss: 1.0669015944004059 , accuracy: 0.668\n",
      "New min loss: 1.0669015944004059\n",
      "55 ) Training: loss: 1.0572399312799627 , accuracy: 0.6812857142857143\n",
      "Validation: loss: 1.0661472529172897 , accuracy: 0.669\n",
      "New min loss: 1.0661472529172897\n",
      "56 ) Training: loss: 1.056412236257033 , accuracy: 0.6822857142857143\n",
      "Validation: loss: 1.0654203593730927 , accuracy: 0.671\n",
      "New min loss: 1.0654203593730927\n",
      "57 ) Training: loss: 1.055605667287653 , accuracy: 0.6834285714285714\n",
      "Validation: loss: 1.0646830201148987 , accuracy: 0.672\n",
      "New min loss: 1.0646830201148987\n",
      "58 ) Training: loss: 1.0548101793635976 , accuracy: 0.6844285714285714\n",
      "Validation: loss: 1.0639286488294601 , accuracy: 0.671\n",
      "New min loss: 1.0639286488294601\n",
      "59 ) Training: loss: 1.0540220434015448 , accuracy: 0.685\n",
      "Validation: loss: 1.0631804466247559 , accuracy: 0.67\n",
      "New min loss: 1.0631804466247559\n",
      "60 ) Training: loss: 1.0532354972579263 , accuracy: 0.6858571428571428\n",
      "Validation: loss: 1.0624092370271683 , accuracy: 0.67\n",
      "New min loss: 1.0624092370271683\n",
      "61 ) Training: loss: 1.0524376717480746 , accuracy: 0.6867142857142857\n",
      "Validation: loss: 1.0616337209939957 , accuracy: 0.671\n",
      "New min loss: 1.0616337209939957\n",
      "62 ) Training: loss: 1.0516300862485712 , accuracy: 0.6867142857142857\n",
      "Validation: loss: 1.0608622431755066 , accuracy: 0.672\n",
      "New min loss: 1.0608622431755066\n",
      "63 ) Training: loss: 1.0507988366213712 , accuracy: 0.6877142857142857\n",
      "Validation: loss: 1.060068517923355 , accuracy: 0.671\n",
      "New min loss: 1.060068517923355\n",
      "64 ) Training: loss: 1.049942433834076 , accuracy: 0.688\n",
      "Validation: loss: 1.0593053698539734 , accuracy: 0.67\n",
      "New min loss: 1.0593053698539734\n",
      "65 ) Training: loss: 1.049062570658597 , accuracy: 0.6884285714285714\n",
      "Validation: loss: 1.0585731714963913 , accuracy: 0.672\n",
      "New min loss: 1.0585731714963913\n",
      "66 ) Training: loss: 1.0481718681075356 , accuracy: 0.6897142857142857\n",
      "Validation: loss: 1.0578874945640564 , accuracy: 0.674\n",
      "New min loss: 1.0578874945640564\n",
      "67 ) Training: loss: 1.0472787575288252 , accuracy: 0.6917142857142857\n",
      "Validation: loss: 1.0572730600833893 , accuracy: 0.674\n",
      "New min loss: 1.0572730600833893\n",
      "68 ) Training: loss: 1.046392221884294 , accuracy: 0.6932857142857143\n",
      "Validation: loss: 1.056699052453041 , accuracy: 0.674\n",
      "New min loss: 1.056699052453041\n",
      "69 ) Training: loss: 1.045498269254511 , accuracy: 0.6941428571428572\n",
      "Validation: loss: 1.0561895966529846 , accuracy: 0.678\n",
      "New min loss: 1.0561895966529846\n",
      "70 ) Training: loss: 1.0445845766500994 , accuracy: 0.6954285714285714\n",
      "Validation: loss: 1.055697351694107 , accuracy: 0.678\n",
      "New min loss: 1.055697351694107\n",
      "71 ) Training: loss: 1.043647942759774 , accuracy: 0.6955714285714286\n",
      "Validation: loss: 1.0552175492048264 , accuracy: 0.676\n",
      "New min loss: 1.0552175492048264\n",
      "72 ) Training: loss: 1.0426838213747198 , accuracy: 0.6958571428571428\n",
      "Validation: loss: 1.0547605007886887 , accuracy: 0.674\n",
      "New min loss: 1.0547605007886887\n",
      "73 ) Training: loss: 1.041692963513461 , accuracy: 0.6971428571428572\n",
      "Validation: loss: 1.0542334616184235 , accuracy: 0.672\n",
      "New min loss: 1.0542334616184235\n",
      "74 ) Training: loss: 1.0406775637106462 , accuracy: 0.6997142857142857\n",
      "Validation: loss: 1.0537094920873642 , accuracy: 0.673\n",
      "New min loss: 1.0537094920873642\n",
      "75 ) Training: loss: 1.039633159203963 , accuracy: 0.701\n",
      "Validation: loss: 1.053201973438263 , accuracy: 0.673\n",
      "New min loss: 1.053201973438263\n",
      "76 ) Training: loss: 1.0385584061796016 , accuracy: 0.7012857142857143\n",
      "Validation: loss: 1.0526564419269562 , accuracy: 0.675\n",
      "New min loss: 1.0526564419269562\n",
      "77 ) Training: loss: 1.0374483466148376 , accuracy: 0.7034285714285714\n",
      "Validation: loss: 1.0520921498537064 , accuracy: 0.677\n",
      "New min loss: 1.0520921498537064\n",
      "78 ) Training: loss: 1.0362973050637678 , accuracy: 0.706\n",
      "Validation: loss: 1.051455870270729 , accuracy: 0.678\n",
      "New min loss: 1.051455870270729\n",
      "79 ) Training: loss: 1.0350856455889614 , accuracy: 0.7074285714285714\n",
      "Validation: loss: 1.0507122576236725 , accuracy: 0.681\n",
      "New min loss: 1.0507122576236725\n",
      "80 ) Training: loss: 1.0338085944002324 , accuracy: 0.7087142857142857\n",
      "Validation: loss: 1.049698069691658 , accuracy: 0.681\n",
      "New min loss: 1.049698069691658\n",
      "81 ) Training: loss: 1.0324469739740545 , accuracy: 0.7124285714285714\n",
      "Validation: loss: 1.0486919581890106 , accuracy: 0.678\n",
      "New min loss: 1.0486919581890106\n",
      "82 ) Training: loss: 1.0310106895186684 , accuracy: 0.7137142857142857\n",
      "Validation: loss: 1.047665759921074 , accuracy: 0.68\n",
      "New min loss: 1.047665759921074\n",
      "83 ) Training: loss: 1.0295142618092623 , accuracy: 0.7157142857142857\n",
      "Validation: loss: 1.0467974990606308 , accuracy: 0.68\n",
      "New min loss: 1.0467974990606308\n",
      "84 ) Training: loss: 1.0279926950281317 , accuracy: 0.7174285714285714\n",
      "Validation: loss: 1.045887604355812 , accuracy: 0.68\n",
      "New min loss: 1.045887604355812\n",
      "85 ) Training: loss: 1.0264586611227555 , accuracy: 0.7177142857142857\n",
      "Validation: loss: 1.0447271317243576 , accuracy: 0.68\n",
      "New min loss: 1.0447271317243576\n",
      "86 ) Training: loss: 1.0249034903266214 , accuracy: 0.7188571428571429\n",
      "Validation: loss: 1.0432748049497604 , accuracy: 0.681\n",
      "New min loss: 1.0432748049497604\n",
      "87 ) Training: loss: 1.023315417766571 , accuracy: 0.7211428571428572\n",
      "Validation: loss: 1.0415327101945877 , accuracy: 0.685\n",
      "New min loss: 1.0415327101945877\n",
      "88 ) Training: loss: 1.0216878685084256 , accuracy: 0.723\n",
      "Validation: loss: 1.0396578907966614 , accuracy: 0.688\n",
      "New min loss: 1.0396578907966614\n",
      "89 ) Training: loss: 1.0200446118008006 , accuracy: 0.7254285714285714\n",
      "Validation: loss: 1.0376031249761581 , accuracy: 0.693\n",
      "New min loss: 1.0376031249761581\n",
      "90 ) Training: loss: 1.018379072709517 , accuracy: 0.7281428571428571\n",
      "Validation: loss: 1.0356283783912659 , accuracy: 0.694\n",
      "New min loss: 1.0356283783912659\n",
      "91 ) Training: loss: 1.0167133634740657 , accuracy: 0.7291428571428571\n",
      "Validation: loss: 1.033569723367691 , accuracy: 0.697\n",
      "New min loss: 1.033569723367691\n",
      "92 ) Training: loss: 1.015055362744765 , accuracy: 0.732\n",
      "Validation: loss: 1.0314895063638687 , accuracy: 0.701\n",
      "New min loss: 1.0314895063638687\n",
      "93 ) Training: loss: 1.0134049274704673 , accuracy: 0.7348571428571429\n",
      "Validation: loss: 1.02947898209095 , accuracy: 0.704\n",
      "New min loss: 1.02947898209095\n",
      "94 ) Training: loss: 1.0117803779515353 , accuracy: 0.7357142857142858\n",
      "Validation: loss: 1.0274166017770767 , accuracy: 0.708\n",
      "New min loss: 1.0274166017770767\n",
      "95 ) Training: loss: 1.010195908763192 , accuracy: 0.7378571428571429\n",
      "Validation: loss: 1.0255516469478607 , accuracy: 0.712\n",
      "New min loss: 1.0255516469478607\n",
      "96 ) Training: loss: 1.0086518742821433 , accuracy: 0.739\n",
      "Validation: loss: 1.0237692445516586 , accuracy: 0.714\n",
      "New min loss: 1.0237692445516586\n",
      "97 ) Training: loss: 1.0071349761702797 , accuracy: 0.7412857142857143\n",
      "Validation: loss: 1.022186741232872 , accuracy: 0.716\n",
      "New min loss: 1.022186741232872\n",
      "98 ) Training: loss: 1.0056633884256536 , accuracy: 0.7431428571428571\n",
      "Validation: loss: 1.0206944346427917 , accuracy: 0.714\n",
      "New min loss: 1.0206944346427917\n",
      "99 ) Training: loss: 1.0042799017646096 , accuracy: 0.7452857142857143\n",
      "Validation: loss: 1.0192449018359184 , accuracy: 0.715\n",
      "New min loss: 1.0192449018359184\n",
      "100 ) Training: loss: 1.0029244921424172 , accuracy: 0.7462857142857143\n",
      "Validation: loss: 1.017893448472023 , accuracy: 0.716\n",
      "New min loss: 1.017893448472023\n",
      "101 ) Training: loss: 1.001589672131972 , accuracy: 0.7465714285714286\n",
      "Validation: loss: 1.0166627019643784 , accuracy: 0.719\n",
      "New min loss: 1.0166627019643784\n",
      "102 ) Training: loss: 1.0002849080345848 , accuracy: 0.7465714285714286\n",
      "Validation: loss: 1.0156114473938942 , accuracy: 0.719\n",
      "New min loss: 1.0156114473938942\n",
      "103 ) Training: loss: 0.9990834712982177 , accuracy: 0.7477142857142857\n",
      "Validation: loss: 1.0146538689732552 , accuracy: 0.723\n",
      "New min loss: 1.0146538689732552\n",
      "104 ) Training: loss: 0.9979164448651401 , accuracy: 0.7482857142857143\n",
      "Validation: loss: 1.0137657970190048 , accuracy: 0.725\n",
      "New min loss: 1.0137657970190048\n",
      "105 ) Training: loss: 0.9968318007209084 , accuracy: 0.7501428571428571\n",
      "Validation: loss: 1.0128989070653915 , accuracy: 0.725\n",
      "New min loss: 1.0128989070653915\n",
      "106 ) Training: loss: 0.9957617055286061 , accuracy: 0.7507142857142857\n",
      "Validation: loss: 1.0121049731969833 , accuracy: 0.725\n",
      "New min loss: 1.0121049731969833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 ) Training: loss: 0.9947688752954656 , accuracy: 0.751\n",
      "Validation: loss: 1.011306531727314 , accuracy: 0.726\n",
      "New min loss: 1.011306531727314\n",
      "108 ) Training: loss: 0.9937663793563842 , accuracy: 0.7522857142857143\n",
      "Validation: loss: 1.0105990767478943 , accuracy: 0.725\n",
      "New min loss: 1.0105990767478943\n",
      "109 ) Training: loss: 0.9927439592101357 , accuracy: 0.7531428571428571\n",
      "Validation: loss: 1.009976089000702 , accuracy: 0.726\n",
      "New min loss: 1.009976089000702\n",
      "110 ) Training: loss: 0.9917670239101757 , accuracy: 0.7544285714285714\n",
      "Validation: loss: 1.0095689445734024 , accuracy: 0.726\n",
      "New min loss: 1.0095689445734024\n",
      "111 ) Training: loss: 0.9908423033627597 , accuracy: 0.755\n",
      "Validation: loss: 1.0090797618031502 , accuracy: 0.726\n",
      "New min loss: 1.0090797618031502\n",
      "112 ) Training: loss: 0.9899144107645208 , accuracy: 0.7555714285714286\n",
      "Validation: loss: 1.008830040693283 , accuracy: 0.73\n",
      "New min loss: 1.008830040693283\n",
      "113 ) Training: loss: 0.989085725220767 , accuracy: 0.7571428571428571\n",
      "Validation: loss: 1.0085211992263794 , accuracy: 0.731\n",
      "New min loss: 1.0085211992263794\n",
      "114 ) Training: loss: 0.9882418740879405 , accuracy: 0.7578571428571429\n",
      "Validation: loss: 1.008239783346653 , accuracy: 0.734\n",
      "New min loss: 1.008239783346653\n",
      "115 ) Training: loss: 0.9874246738173745 , accuracy: 0.7575714285714286\n",
      "Validation: loss: 1.0078580304980278 , accuracy: 0.732\n",
      "New min loss: 1.0078580304980278\n",
      "116 ) Training: loss: 0.9866110216487538 , accuracy: 0.7587142857142857\n",
      "Validation: loss: 1.0074969455599785 , accuracy: 0.732\n",
      "New min loss: 1.0074969455599785\n",
      "117 ) Training: loss: 0.9857848969372836 , accuracy: 0.7591428571428571\n",
      "Validation: loss: 1.0072288662195206 , accuracy: 0.731\n",
      "New min loss: 1.0072288662195206\n",
      "118 ) Training: loss: 0.9849911299618808 , accuracy: 0.7605714285714286\n",
      "Validation: loss: 1.0069616883993149 , accuracy: 0.732\n",
      "New min loss: 1.0069616883993149\n",
      "119 ) Training: loss: 0.9842255039648576 , accuracy: 0.7605714285714286\n",
      "Validation: loss: 1.006582647562027 , accuracy: 0.731\n",
      "New min loss: 1.006582647562027\n",
      "120 ) Training: loss: 0.983435122533278 , accuracy: 0.7614285714285715\n",
      "Validation: loss: 1.006004735827446 , accuracy: 0.731\n",
      "New min loss: 1.006004735827446\n",
      "121 ) Training: loss: 0.9826410163532604 , accuracy: 0.7624285714285715\n",
      "Validation: loss: 1.0056267231702805 , accuracy: 0.73\n",
      "New min loss: 1.0056267231702805\n",
      "122 ) Training: loss: 0.9818793784488331 , accuracy: 0.7638571428571429\n",
      "Validation: loss: 1.0052055194973946 , accuracy: 0.733\n",
      "New min loss: 1.0052055194973946\n",
      "123 ) Training: loss: 0.9810852538455617 , accuracy: 0.7634285714285715\n",
      "Validation: loss: 1.0047682970762253 , accuracy: 0.734\n",
      "New min loss: 1.0047682970762253\n",
      "124 ) Training: loss: 0.9803025874224576 , accuracy: 0.764\n",
      "Validation: loss: 1.0044146627187729 , accuracy: 0.733\n",
      "New min loss: 1.0044146627187729\n",
      "125 ) Training: loss: 0.9795412020249801 , accuracy: 0.764\n",
      "Validation: loss: 1.0040494054555893 , accuracy: 0.734\n",
      "New min loss: 1.0040494054555893\n",
      "126 ) Training: loss: 0.9787730357863687 , accuracy: 0.7654285714285715\n",
      "Validation: loss: 1.003662459552288 , accuracy: 0.734\n",
      "New min loss: 1.003662459552288\n",
      "127 ) Training: loss: 0.978078521381725 , accuracy: 0.7665714285714286\n",
      "Validation: loss: 1.0032459422945976 , accuracy: 0.736\n",
      "New min loss: 1.0032459422945976\n",
      "128 ) Training: loss: 0.9774255145679821 , accuracy: 0.7675714285714286\n",
      "Validation: loss: 1.0030815228819847 , accuracy: 0.736\n",
      "New min loss: 1.0030815228819847\n",
      "129 ) Training: loss: 0.9768310557712209 , accuracy: 0.769\n",
      "Validation: loss: 1.0027085915207863 , accuracy: 0.737\n",
      "New min loss: 1.0027085915207863\n",
      "130 ) Training: loss: 0.9762828935276379 , accuracy: 0.7698571428571429\n",
      "Validation: loss: 1.0024294704198837 , accuracy: 0.737\n",
      "New min loss: 1.0024294704198837\n",
      "131 ) Training: loss: 0.9757476156408137 , accuracy: 0.7697142857142857\n",
      "Validation: loss: 1.0022199526429176 , accuracy: 0.737\n",
      "New min loss: 1.0022199526429176\n",
      "132 ) Training: loss: 0.9751951932907105 , accuracy: 0.7705714285714286\n",
      "Validation: loss: 1.0020153671503067 , accuracy: 0.736\n",
      "New min loss: 1.0020153671503067\n",
      "133 ) Training: loss: 0.9746973568742926 , accuracy: 0.7715714285714286\n",
      "Validation: loss: 1.0022279545664787 , accuracy: 0.734\n",
      "134 ) Training: loss: 0.9742297443476591 , accuracy: 0.7727142857142857\n",
      "Validation: loss: 1.0022510588169098 , accuracy: 0.735\n",
      "135 ) Training: loss: 0.9737757520242171 , accuracy: 0.7728571428571429\n",
      "Validation: loss: 1.002510853111744 , accuracy: 0.734\n",
      "136 ) Training: loss: 0.9732930942015214 , accuracy: 0.7737142857142857\n",
      "Validation: loss: 1.0026742294430733 , accuracy: 0.733\n",
      "137 ) Training: loss: 0.972767938267101 , accuracy: 0.7738571428571429\n",
      "Validation: loss: 1.002547025680542 , accuracy: 0.734\n",
      "138 ) Training: loss: 0.9722570484334773 , accuracy: 0.7747142857142857\n",
      "Validation: loss: 1.0026838406920433 , accuracy: 0.734\n",
      "139 ) Training: loss: 0.9717794331637296 , accuracy: 0.7748571428571429\n",
      "Validation: loss: 1.0026409551501274 , accuracy: 0.735\n",
      "140 ) Training: loss: 0.9712729508226569 , accuracy: 0.7752857142857142\n",
      "Validation: loss: 1.0025247931480408 , accuracy: 0.735\n",
      "141 ) Training: loss: 0.970791651985862 , accuracy: 0.7764285714285715\n",
      "Validation: loss: 1.0025071874260902 , accuracy: 0.735\n",
      "142 ) Training: loss: 0.9702813809568231 , accuracy: 0.7765714285714286\n",
      "Validation: loss: 1.0020507499575615 , accuracy: 0.737\n",
      "143 ) Training: loss: 0.9697650270028548 , accuracy: 0.7765714285714286\n",
      "Validation: loss: 1.0018481463193893 , accuracy: 0.737\n",
      "New min loss: 1.0018481463193893\n",
      "144 ) Training: loss: 0.969285744970495 , accuracy: 0.7765714285714286\n",
      "Validation: loss: 1.0015353485941887 , accuracy: 0.736\n",
      "New min loss: 1.0015353485941887\n",
      "145 ) Training: loss: 0.9688058322126215 , accuracy: 0.7774285714285715\n",
      "Validation: loss: 1.0014153346419334 , accuracy: 0.736\n",
      "New min loss: 1.0014153346419334\n",
      "146 ) Training: loss: 0.96831721609289 , accuracy: 0.7775714285714286\n",
      "Validation: loss: 1.0012662634253502 , accuracy: 0.736\n",
      "New min loss: 1.0012662634253502\n",
      "147 ) Training: loss: 0.9678591067140753 , accuracy: 0.7778571428571428\n",
      "Validation: loss: 1.0012665018439293 , accuracy: 0.736\n",
      "148 ) Training: loss: 0.9674097050320019 , accuracy: 0.7785714285714286\n",
      "Validation: loss: 1.001479983329773 , accuracy: 0.735\n",
      "149 ) Training: loss: 0.9669734987345608 , accuracy: 0.7792857142857142\n",
      "Validation: loss: 1.0010621100664139 , accuracy: 0.734\n",
      "New min loss: 1.0010621100664139\n",
      "150 ) Training: loss: 0.966513146053661 , accuracy: 0.7798571428571428\n",
      "Validation: loss: 1.0003212168812752 , accuracy: 0.734\n",
      "New min loss: 1.0003212168812752\n",
      "151 ) Training: loss: 0.9660625837065957 , accuracy: 0.7804285714285715\n",
      "Validation: loss: 0.9995713979005814 , accuracy: 0.733\n",
      "New min loss: 0.9995713979005814\n",
      "152 ) Training: loss: 0.9656241601163691 , accuracy: 0.7804285714285715\n",
      "Validation: loss: 0.9984105378389359 , accuracy: 0.734\n",
      "New min loss: 0.9984105378389359\n",
      "153 ) Training: loss: 0.9651938232508572 , accuracy: 0.781\n",
      "Validation: loss: 0.9966296628117561 , accuracy: 0.736\n",
      "New min loss: 0.9966296628117561\n",
      "154 ) Training: loss: 0.9647239316593517 , accuracy: 0.7817142857142857\n",
      "Validation: loss: 0.9951780140399933 , accuracy: 0.743\n",
      "New min loss: 0.9951780140399933\n",
      "155 ) Training: loss: 0.964245693250136 , accuracy: 0.7824285714285715\n",
      "Validation: loss: 0.9922690093517303 , accuracy: 0.744\n",
      "New min loss: 0.9922690093517303\n",
      "156 ) Training: loss: 0.9636831218546087 , accuracy: 0.7831428571428571\n",
      "Validation: loss: 0.9896562993526459 , accuracy: 0.747\n",
      "New min loss: 0.9896562993526459\n",
      "157 ) Training: loss: 0.9631249872120944 , accuracy: 0.7834285714285715\n",
      "Validation: loss: 0.987394668161869 , accuracy: 0.747\n",
      "New min loss: 0.987394668161869\n",
      "158 ) Training: loss: 0.9626160632480275 , accuracy: 0.7838571428571428\n",
      "Validation: loss: 0.9860491901636124 , accuracy: 0.75\n",
      "New min loss: 0.9860491901636124\n",
      "159 ) Training: loss: 0.9621821381829002 , accuracy: 0.7837142857142857\n",
      "Validation: loss: 0.9844070002436638 , accuracy: 0.759\n",
      "New min loss: 0.9844070002436638\n",
      "160 ) Training: loss: 0.9617436604066328 , accuracy: 0.7842857142857143\n",
      "Validation: loss: 0.9848547056317329 , accuracy: 0.755\n",
      "161 ) Training: loss: 0.961308706890453 , accuracy: 0.7842857142857143\n",
      "Validation: loss: 0.9840636029839516 , accuracy: 0.756\n",
      "New min loss: 0.9840636029839516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 ) Training: loss: 0.9608332547274503 , accuracy: 0.7861428571428571\n",
      "Validation: loss: 0.984900526702404 , accuracy: 0.754\n",
      "163 ) Training: loss: 0.9604434230110862 , accuracy: 0.7864285714285715\n",
      "Validation: loss: 0.9837164878845215 , accuracy: 0.756\n",
      "New min loss: 0.9837164878845215\n",
      "164 ) Training: loss: 0.9599592133001847 , accuracy: 0.787\n",
      "Validation: loss: 0.9837033450603485 , accuracy: 0.756\n",
      "New min loss: 0.9837033450603485\n",
      "165 ) Training: loss: 0.959550107609142 , accuracy: 0.7874285714285715\n",
      "Validation: loss: 0.9838902652263641 , accuracy: 0.755\n",
      "166 ) Training: loss: 0.9591830318624323 , accuracy: 0.7874285714285715\n",
      "Validation: loss: 0.9829632118344307 , accuracy: 0.758\n",
      "New min loss: 0.9829632118344307\n",
      "167 ) Training: loss: 0.9587474443695762 , accuracy: 0.7884285714285715\n",
      "Validation: loss: 0.9832620769739151 , accuracy: 0.755\n",
      "168 ) Training: loss: 0.9584137732332403 , accuracy: 0.79\n",
      "Validation: loss: 0.9827674329280853 , accuracy: 0.757\n",
      "New min loss: 0.9827674329280853\n",
      "169 ) Training: loss: 0.957886045629328 , accuracy: 0.7901428571428571\n",
      "Validation: loss: 0.9838983193039894 , accuracy: 0.754\n",
      "170 ) Training: loss: 0.9575084090232849 , accuracy: 0.7911428571428571\n",
      "Validation: loss: 0.9842740818858147 , accuracy: 0.755\n",
      "171 ) Training: loss: 0.9572051741860129 , accuracy: 0.7917142857142857\n",
      "Validation: loss: 0.982019454240799 , accuracy: 0.757\n",
      "New min loss: 0.982019454240799\n",
      "172 ) Training: loss: 0.9566751014102589 , accuracy: 0.7914285714285715\n",
      "Validation: loss: 0.9807763025164604 , accuracy: 0.761\n",
      "New min loss: 0.9807763025164604\n",
      "173 ) Training: loss: 0.9561274788596413 , accuracy: 0.7934285714285715\n",
      "Validation: loss: 0.9847559705376625 , accuracy: 0.756\n",
      "174 ) Training: loss: 0.9567065434022384 , accuracy: 0.7908571428571428\n",
      "Validation: loss: 0.9814961403608322 , accuracy: 0.756\n",
      "175 ) Training: loss: 0.9564003229141236 , accuracy: 0.7908571428571428\n",
      "Validation: loss: 0.9813341349363327 , accuracy: 0.76\n",
      "176 ) Training: loss: 0.9560824816877191 , accuracy: 0.7912857142857143\n",
      "Validation: loss: 0.9812935143709183 , accuracy: 0.756\n",
      "177 ) Training: loss: 0.956917608867992 , accuracy: 0.7904285714285715\n",
      "Validation: loss: 0.9809749126434326 , accuracy: 0.76\n",
      "178 ) Training: loss: 0.9537341497161171 , accuracy: 0.7947142857142857\n",
      "Validation: loss: 0.9810860008001328 , accuracy: 0.76\n",
      "179 ) Training: loss: 0.9555783911184831 , accuracy: 0.7918571428571428\n",
      "Validation: loss: 0.9804489612579346 , accuracy: 0.761\n",
      "New min loss: 0.9804489612579346\n",
      "180 ) Training: loss: 0.9557018626819958 , accuracy: 0.7914285714285715\n",
      "Validation: loss: 0.980448842048645 , accuracy: 0.76\n",
      "New min loss: 0.980448842048645\n",
      "181 ) Training: loss: 0.9550641699270769 , accuracy: 0.7925714285714286\n",
      "Validation: loss: 0.9806763678789139 , accuracy: 0.758\n",
      "182 ) Training: loss: 0.9551436554301869 , accuracy: 0.7918571428571428\n",
      "Validation: loss: 0.9803983271121979 , accuracy: 0.759\n",
      "New min loss: 0.9803983271121979\n",
      "183 ) Training: loss: 0.9549446539445356 , accuracy: 0.7937142857142857\n",
      "Validation: loss: 0.9803836345672607 , accuracy: 0.759\n",
      "New min loss: 0.9803836345672607\n",
      "184 ) Training: loss: 0.9542865666476164 , accuracy: 0.7942857142857143\n",
      "Validation: loss: 0.9808169603347778 , accuracy: 0.758\n",
      "185 ) Training: loss: 0.9530467542735013 , accuracy: 0.795\n",
      "Validation: loss: 0.9816627353429794 , accuracy: 0.758\n",
      "186 ) Training: loss: 0.9521315466273915 , accuracy: 0.7968571428571428\n",
      "Validation: loss: 0.982944019138813 , accuracy: 0.762\n",
      "187 ) Training: loss: 0.9523893063718623 , accuracy: 0.7947142857142857\n",
      "Validation: loss: 0.9889839217066765 , accuracy: 0.745\n",
      "188 ) Training: loss: 0.9517441717061129 , accuracy: 0.7964285714285714\n",
      "Validation: loss: 0.9947426468133926 , accuracy: 0.74\n",
      "189 ) Training: loss: 0.9508372111753984 , accuracy: 0.7981428571428572\n",
      "Validation: loss: 0.9898905381560326 , accuracy: 0.743\n",
      "190 ) Training: loss: 0.9499853838573803 , accuracy: 0.799\n",
      "Validation: loss: 0.9957199022173882 , accuracy: 0.737\n",
      "191 ) Training: loss: 0.949284372546456 , accuracy: 0.7994285714285714\n",
      "Validation: loss: 0.9989432319998741 , accuracy: 0.735\n",
      "192 ) Training: loss: 0.9488077532161366 , accuracy: 0.8002857142857143\n",
      "Validation: loss: 0.9941086173057556 , accuracy: 0.742\n",
      "193 ) Training: loss: 0.9479219555854798 , accuracy: 0.8028571428571428\n",
      "Validation: loss: 0.9941747039556503 , accuracy: 0.739\n",
      "194 ) Training: loss: 0.9480817079544067 , accuracy: 0.8025714285714286\n",
      "Validation: loss: 0.9843368753790855 , accuracy: 0.755\n",
      "195 ) Training: loss: 0.9475039958953857 , accuracy: 0.8031428571428572\n",
      "Validation: loss: 1.0038672983646393 , accuracy: 0.729\n",
      "196 ) Training: loss: 0.9489297043193471 , accuracy: 0.8005714285714286\n",
      "Validation: loss: 1.0021505802869797 , accuracy: 0.732\n",
      "197 ) Training: loss: 0.947150486165827 , accuracy: 0.803\n",
      "Validation: loss: 0.9832911863923073 , accuracy: 0.757\n",
      "198 ) Training: loss: 0.9469886920668862 , accuracy: 0.8025714285714286\n",
      "Validation: loss: 0.9805838465690613 , accuracy: 0.767\n",
      "199 ) Training: loss: 0.9474983887238936 , accuracy: 0.8008571428571428\n",
      "Validation: loss: 1.0015781074762344 , accuracy: 0.734\n",
      "200 ) Training: loss: 0.947251296043396 , accuracy: 0.8012857142857143\n",
      "Validation: loss: 0.9847950488328934 , accuracy: 0.754\n",
      "201 ) Training: loss: 0.9468332106416876 , accuracy: 0.8012857142857143\n",
      "Validation: loss: 1.0019658505916595 , accuracy: 0.734\n",
      "202 ) Training: loss: 0.9472859512675892 , accuracy: 0.7994285714285714\n",
      "Validation: loss: 0.9987674281001091 , accuracy: 0.737\n",
      "203 ) Training: loss: 0.9459955117919229 , accuracy: 0.803\n",
      "Validation: loss: 1.0005792379379272 , accuracy: 0.735\n",
      "204 ) Training: loss: 0.9459311571988193 , accuracy: 0.8017142857142857\n",
      "Validation: loss: 1.0025530382990837 , accuracy: 0.734\n",
      "205 ) Training: loss: 0.946042065186934 , accuracy: 0.8017142857142857\n",
      "Validation: loss: 0.9841073080897331 , accuracy: 0.755\n",
      "206 ) Training: loss: 0.9452508124438199 , accuracy: 0.8037142857142857\n",
      "Validation: loss: 0.9947673678398132 , accuracy: 0.745\n",
      "207 ) Training: loss: 0.9448463288220492 , accuracy: 0.8034285714285714\n",
      "Validation: loss: 1.0016133189201355 , accuracy: 0.738\n",
      "208 ) Training: loss: 0.9437291394580495 , accuracy: 0.8052857142857143\n",
      "Validation: loss: 0.9901769384741783 , accuracy: 0.746\n",
      "209 ) Training: loss: 0.9438317060470581 , accuracy: 0.8044285714285714\n",
      "Validation: loss: 0.9986295029520988 , accuracy: 0.74\n",
      "210 ) Training: loss: 0.9432442567565225 , accuracy: 0.8051428571428572\n",
      "Validation: loss: 1.0004055052995682 , accuracy: 0.737\n",
      "211 ) Training: loss: 0.9431906808506358 , accuracy: 0.8054285714285714\n",
      "Validation: loss: 0.999275453388691 , accuracy: 0.739\n",
      "212 ) Training: loss: 0.9425737261772156 , accuracy: 0.8068571428571428\n",
      "Validation: loss: 0.9987209588289261 , accuracy: 0.739\n",
      "213 ) Training: loss: 0.9421587694774974 , accuracy: 0.8071428571428572\n",
      "Validation: loss: 0.9982114881277084 , accuracy: 0.738\n",
      "214 ) Training: loss: 0.9415432290597395 , accuracy: 0.8072857142857143\n",
      "Validation: loss: 0.9975202977657318 , accuracy: 0.738\n",
      "215 ) Training: loss: 0.9410849527879195 , accuracy: 0.8082857142857143\n",
      "Validation: loss: 0.9968681409955025 , accuracy: 0.738\n",
      "216 ) Training: loss: 0.9406248905441977 , accuracy: 0.8082857142857143\n",
      "Validation: loss: 0.996295839548111 , accuracy: 0.739\n",
      "217 ) Training: loss: 0.9401772845875133 , accuracy: 0.8082857142857143\n",
      "Validation: loss: 0.9956709295511246 , accuracy: 0.74\n",
      "218 ) Training: loss: 0.9397339289838618 , accuracy: 0.8077142857142857\n",
      "Validation: loss: 0.9956623241305351 , accuracy: 0.741\n",
      "219 ) Training: loss: 0.9394465598193082 , accuracy: 0.8087142857142857\n",
      "Validation: loss: 0.9934420213103294 , accuracy: 0.742\n",
      "220 ) Training: loss: 0.9396818627010692 , accuracy: 0.8097142857142857\n",
      "Validation: loss: 0.9942908957600594 , accuracy: 0.743\n",
      "221 ) Training: loss: 0.9413120584054426 , accuracy: 0.8058571428571428\n",
      "Validation: loss: 0.9939645081758499 , accuracy: 0.744\n",
      "222 ) Training: loss: 0.9410493352196433 , accuracy: 0.8071428571428572\n",
      "Validation: loss: 0.9796584919095039 , accuracy: 0.759\n",
      "New min loss: 0.9796584919095039\n",
      "223 ) Training: loss: 0.9396904522722418 , accuracy: 0.8094285714285714\n",
      "Validation: loss: 0.9788395762443542 , accuracy: 0.761\n",
      "New min loss: 0.9788395762443542\n",
      "224 ) Training: loss: 0.9400313713333823 , accuracy: 0.807\n",
      "Validation: loss: 0.9782102406024933 , accuracy: 0.762\n",
      "New min loss: 0.9782102406024933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 ) Training: loss: 0.9389621290293607 , accuracy: 0.8102857142857143\n",
      "Validation: loss: 0.9800456389784813 , accuracy: 0.757\n",
      "226 ) Training: loss: 0.9393357146870006 , accuracy: 0.8078571428571428\n",
      "Validation: loss: 0.9954699873924255 , accuracy: 0.744\n",
      "227 ) Training: loss: 0.939192778413946 , accuracy: 0.8085714285714286\n",
      "Validation: loss: 0.9878449887037277 , accuracy: 0.746\n",
      "228 ) Training: loss: 0.9378655184398997 , accuracy: 0.8108571428571428\n",
      "Validation: loss: 0.9807873964309692 , accuracy: 0.754\n",
      "229 ) Training: loss: 0.9377633105624806 , accuracy: 0.8104285714285714\n",
      "Validation: loss: 0.9870016649365425 , accuracy: 0.746\n",
      "230 ) Training: loss: 0.9371191404082558 , accuracy: 0.8105714285714286\n",
      "Validation: loss: 0.9917815774679184 , accuracy: 0.744\n",
      "231 ) Training: loss: 0.9379108797420155 , accuracy: 0.8108571428571428\n",
      "Validation: loss: 0.9902576133608818 , accuracy: 0.749\n",
      "232 ) Training: loss: 0.9375373753634366 , accuracy: 0.811\n",
      "Validation: loss: 0.9784493967890739 , accuracy: 0.761\n",
      "233 ) Training: loss: 0.9363607027313926 , accuracy: 0.8125714285714286\n",
      "Validation: loss: 0.9814474359154701 , accuracy: 0.756\n",
      "234 ) Training: loss: 0.935524751923301 , accuracy: 0.8137142857142857\n",
      "Validation: loss: 0.9791647791862488 , accuracy: 0.76\n",
      "235 ) Training: loss: 0.9354985529726202 , accuracy: 0.8138571428571428\n",
      "Validation: loss: 0.9831713363528252 , accuracy: 0.751\n",
      "236 ) Training: loss: 0.9353925574909557 , accuracy: 0.8132857142857143\n",
      "Validation: loss: 0.9825521782040596 , accuracy: 0.75\n",
      "237 ) Training: loss: 0.9342618519609625 , accuracy: 0.8145714285714286\n",
      "Validation: loss: 0.9771391451358795 , accuracy: 0.764\n",
      "New min loss: 0.9771391451358795\n",
      "238 ) Training: loss: 0.9362879590554671 , accuracy: 0.8125714285714286\n",
      "Validation: loss: 0.9887611865997314 , accuracy: 0.75\n",
      "239 ) Training: loss: 0.9361463676799427 , accuracy: 0.8121428571428572\n",
      "Validation: loss: 0.977012999355793 , accuracy: 0.764\n",
      "New min loss: 0.977012999355793\n",
      "240 ) Training: loss: 0.9350070660764521 , accuracy: 0.8148571428571428\n",
      "Validation: loss: 0.9856315404176712 , accuracy: 0.75\n",
      "241 ) Training: loss: 0.9331265861337835 , accuracy: 0.8158571428571428\n",
      "Validation: loss: 0.9844430610537529 , accuracy: 0.75\n",
      "242 ) Training: loss: 0.9341926553032615 , accuracy: 0.8151428571428572\n",
      "Validation: loss: 0.9778417721390724 , accuracy: 0.764\n",
      "243 ) Training: loss: 0.9345475673675537 , accuracy: 0.8132857142857143\n",
      "Validation: loss: 0.9779232516884804 , accuracy: 0.763\n",
      "244 ) Training: loss: 0.9333533373746005 , accuracy: 0.8162857142857143\n",
      "Validation: loss: 0.9768881797790527 , accuracy: 0.765\n",
      "New min loss: 0.9768881797790527\n",
      "245 ) Training: loss: 0.9340429316867481 , accuracy: 0.8154285714285714\n",
      "Validation: loss: 0.9770672619342804 , accuracy: 0.762\n",
      "246 ) Training: loss: 0.9332399509169839 , accuracy: 0.817\n",
      "Validation: loss: 0.9770025312900543 , accuracy: 0.766\n",
      "247 ) Training: loss: 0.9328635378317399 , accuracy: 0.8162857142857143\n",
      "Validation: loss: 0.9770561754703522 , accuracy: 0.765\n",
      "248 ) Training: loss: 0.9317867875099182 , accuracy: 0.8172857142857143\n",
      "Validation: loss: 0.9776532799005508 , accuracy: 0.76\n",
      "249 ) Training: loss: 0.9330749598416415 , accuracy: 0.8157142857142857\n",
      "Validation: loss: 0.97779830545187 , accuracy: 0.758\n",
      "250 ) Training: loss: 0.9307468414306641 , accuracy: 0.8188571428571428\n",
      "Validation: loss: 0.9788945391774178 , accuracy: 0.756\n",
      "251 ) Training: loss: 0.9335910244421526 , accuracy: 0.8147142857142857\n",
      "Validation: loss: 0.9766135513782501 , accuracy: 0.761\n",
      "New min loss: 0.9766135513782501\n",
      "252 ) Training: loss: 0.9294020566073331 , accuracy: 0.8198571428571428\n",
      "Validation: loss: 0.9831628352403641 , accuracy: 0.753\n",
      "253 ) Training: loss: 0.9323876868594777 , accuracy: 0.816\n",
      "Validation: loss: 0.9800615459680557 , accuracy: 0.757\n",
      "254 ) Training: loss: 0.9319774519313465 , accuracy: 0.8168571428571428\n",
      "Validation: loss: 0.9777205884456635 , accuracy: 0.761\n",
      "255 ) Training: loss: 0.9286203785376115 , accuracy: 0.8202857142857143\n",
      "Validation: loss: 0.9949656426906586 , accuracy: 0.738\n",
      "256 ) Training: loss: 0.9314762191338972 , accuracy: 0.8175714285714286\n",
      "Validation: loss: 0.9809647500514984 , accuracy: 0.756\n",
      "257 ) Training: loss: 0.9280153111978011 , accuracy: 0.8214285714285714\n",
      "Validation: loss: 1.0058998689055443 , accuracy: 0.725\n",
      "258 ) Training: loss: 0.9309368632056496 , accuracy: 0.8172857142857143\n",
      "Validation: loss: 0.9793867021799088 , accuracy: 0.76\n",
      "259 ) Training: loss: 0.927636351368644 , accuracy: 0.8208571428571428\n",
      "Validation: loss: 1.0216329768300056 , accuracy: 0.713\n",
      "260 ) Training: loss: 0.9307732712138783 , accuracy: 0.8178571428571428\n",
      "Validation: loss: 0.9784445762634277 , accuracy: 0.761\n",
      "261 ) Training: loss: 0.9273324673826044 , accuracy: 0.822\n",
      "Validation: loss: 0.9853241592645645 , accuracy: 0.751\n",
      "262 ) Training: loss: 0.9283605272119696 , accuracy: 0.8205714285714286\n",
      "Validation: loss: 0.9897691011428833 , accuracy: 0.746\n",
      "263 ) Training: loss: 0.9301835396073082 , accuracy: 0.8164285714285714\n",
      "Validation: loss: 0.9972362369298935 , accuracy: 0.735\n",
      "264 ) Training: loss: 0.928878291086717 , accuracy: 0.8197142857142857\n",
      "Validation: loss: 0.9993199855089188 , accuracy: 0.732\n",
      "265 ) Training: loss: 0.9290826927531849 , accuracy: 0.8192857142857143\n",
      "Validation: loss: 1.0092693269252777 , accuracy: 0.725\n",
      "266 ) Training: loss: 0.9293773347681219 , accuracy: 0.8187142857142857\n",
      "Validation: loss: 0.9993769973516464 , accuracy: 0.73\n",
      "267 ) Training: loss: 0.9266389359127392 , accuracy: 0.8222857142857143\n",
      "Validation: loss: 0.989415280520916 , accuracy: 0.744\n",
      "268 ) Training: loss: 0.9264085368676619 , accuracy: 0.823\n",
      "Validation: loss: 0.9952211156487465 , accuracy: 0.737\n",
      "269 ) Training: loss: 0.9268009695139798 , accuracy: 0.8221428571428572\n",
      "Validation: loss: 0.9959404394030571 , accuracy: 0.734\n",
      "270 ) Training: loss: 0.9270067464221607 , accuracy: 0.8218571428571428\n",
      "Validation: loss: 0.9950156658887863 , accuracy: 0.736\n",
      "271 ) Training: loss: 0.9267521468075839 , accuracy: 0.8222857142857143\n",
      "Validation: loss: 0.9964749440550804 , accuracy: 0.737\n",
      "272 ) Training: loss: 0.9261503924023021 , accuracy: 0.8224285714285714\n",
      "Validation: loss: 0.9966908395290375 , accuracy: 0.736\n",
      "273 ) Training: loss: 0.9257661364295265 , accuracy: 0.8224285714285714\n",
      "Validation: loss: 0.9996195659041405 , accuracy: 0.736\n",
      "274 ) Training: loss: 0.9260374816981229 , accuracy: 0.823\n",
      "Validation: loss: 1.001460038125515 , accuracy: 0.735\n",
      "275 ) Training: loss: 0.9270246603272178 , accuracy: 0.8218571428571428\n",
      "Validation: loss: 1.001828283071518 , accuracy: 0.732\n",
      "276 ) Training: loss: 0.9255691029808738 , accuracy: 0.8244285714285714\n",
      "Validation: loss: 1.003616452217102 , accuracy: 0.731\n",
      "277 ) Training: loss: 0.9255055091597817 , accuracy: 0.8225714285714286\n",
      "Validation: loss: 0.9987757652997971 , accuracy: 0.727\n",
      "278 ) Training: loss: 0.9233944968743758 , accuracy: 0.8254285714285714\n",
      "Validation: loss: 0.993827112019062 , accuracy: 0.732\n",
      "279 ) Training: loss: 0.9217983256686818 , accuracy: 0.8272857142857143\n",
      "Validation: loss: 0.9958855733275414 , accuracy: 0.731\n",
      "280 ) Training: loss: 0.9220715067603371 , accuracy: 0.8284285714285714\n",
      "Validation: loss: 0.9939121156930923 , accuracy: 0.733\n",
      "281 ) Training: loss: 0.9221240964802828 , accuracy: 0.8262857142857143\n",
      "Validation: loss: 0.9939813017845154 , accuracy: 0.732\n",
      "282 ) Training: loss: 0.9226341442628341 , accuracy: 0.8267142857142857\n",
      "Validation: loss: 0.9919374659657478 , accuracy: 0.742\n",
      "283 ) Training: loss: 0.9208275762471285 , accuracy: 0.8284285714285714\n",
      "Validation: loss: 0.9961834400892258 , accuracy: 0.732\n",
      "284 ) Training: loss: 0.9232266827063127 , accuracy: 0.8264285714285714\n",
      "Validation: loss: 0.9870716258883476 , accuracy: 0.747\n",
      "285 ) Training: loss: 0.9218104048208757 , accuracy: 0.828\n",
      "Validation: loss: 0.986243762075901 , accuracy: 0.747\n",
      "286 ) Training: loss: 0.9205746607346968 , accuracy: 0.8294285714285714\n",
      "Validation: loss: 0.9850073382258415 , accuracy: 0.749\n",
      "287 ) Training: loss: 0.9200672214681452 , accuracy: 0.8295714285714286\n",
      "Validation: loss: 0.9960182011127472 , accuracy: 0.731\n",
      "288 ) Training: loss: 0.9238562703132629 , accuracy: 0.8242857142857143\n",
      "Validation: loss: 1.0002316012978554 , accuracy: 0.727\n",
      "289 ) Training: loss: 0.9204654000022194 , accuracy: 0.8285714285714286\n",
      "Validation: loss: 0.9913130402565002 , accuracy: 0.739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 ) Training: loss: 0.9195899551564997 , accuracy: 0.831\n",
      "Validation: loss: 0.9881294071674347 , accuracy: 0.744\n",
      "291 ) Training: loss: 0.920532518083399 , accuracy: 0.8281428571428572\n",
      "Validation: loss: 0.985688641667366 , accuracy: 0.749\n",
      "292 ) Training: loss: 0.9195175474340266 , accuracy: 0.8314285714285714\n",
      "Validation: loss: 0.9833519756793976 , accuracy: 0.754\n",
      "293 ) Training: loss: 0.918771598555825 , accuracy: 0.832\n",
      "Validation: loss: 0.9862919822335243 , accuracy: 0.749\n",
      "294 ) Training: loss: 0.9172652678056197 , accuracy: 0.8332857142857143\n",
      "Validation: loss: 0.9832988008856773 , accuracy: 0.754\n",
      "295 ) Training: loss: 0.9193946090611544 , accuracy: 0.8312857142857143\n",
      "Validation: loss: 0.9754425883293152 , accuracy: 0.765\n",
      "New min loss: 0.9754425883293152\n",
      "296 ) Training: loss: 0.9173809506676414 , accuracy: 0.8317142857142857\n",
      "Validation: loss: 0.9919246062636375 , accuracy: 0.741\n",
      "297 ) Training: loss: 0.9171396602283824 , accuracy: 0.833\n",
      "Validation: loss: 0.9791937321424484 , accuracy: 0.759\n",
      "298 ) Training: loss: 0.9176931554620916 , accuracy: 0.8322857142857143\n",
      "Validation: loss: 0.9775492995977402 , accuracy: 0.764\n",
      "299 ) Training: loss: 0.9167325453324752 , accuracy: 0.8325714285714285\n",
      "Validation: loss: 0.9757342040538788 , accuracy: 0.763\n",
      "300 ) Training: loss: 0.9175509962168606 , accuracy: 0.8335714285714285\n",
      "Validation: loss: 0.984501451253891 , accuracy: 0.755\n"
     ]
    }
   ],
   "source": [
    "# HINT: note that your training time should not take more than 2 hours.\n",
    "\n",
    "max_epoch = 300\n",
    "train_batch = 128\n",
    "test_batch = 1\n",
    "learning_rate = 1e-2 #try learning rate from the interval [1e-1, 1e-4]\n",
    "\n",
    "#use_gpu = torch.cuda.is_available()\n",
    "best_path = \"best_cnn_sgd.pth\"\n",
    "# Create train dataset loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch) #batch size 1 for sgd\n",
    "# Create validation dataset loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=train_batch) #batch size 1 for sgd\n",
    "# Create test dataset loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch) #batch size 1 for sgd\n",
    "# initialize your network\n",
    "model = ConvNet()\n",
    "device = torch.device(dev)\n",
    "model = model.to(device)\n",
    "# define your loss function\n",
    "criterion = nn.CrossEntropyLoss()    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=5e-04) # you can play with weight_decay as well but do not add additional parameters \n",
    "# start training\n",
    "# for each epoch calculate validation performance\n",
    "# save best model according to validation performance\n",
    "tr_losses=[]\n",
    "tr_accuracies=[]\n",
    "val_losses=[]\n",
    "val_accuracies=[]\n",
    "i = 1\n",
    "min_loss = np.inf\n",
    "for epoch in range(max_epoch):\n",
    "    model=model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    correct = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        gt = y_batch.data.max(1, keepdim=True)[1]\n",
    "        #print(\"pred:\", pred, \", gt:\", gt)\n",
    "        correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "        epoch_losses.append(loss.item())\n",
    "    accuracy = (correct.item()/len(train_loader.dataset))\n",
    "    tr_accuracies.append(accuracy)\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    tr_losses.append(avg_loss)\n",
    "    print(i,\") Training: loss:\", avg_loss, \", accuracy:\", accuracy)\n",
    "    i += 1\n",
    "\n",
    "    #    Validation\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    correct = 0\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch = batch[0].to(device)\n",
    "            y_batch = batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "            gt = y_batch.data.max(1, keepdim=True)[1]\n",
    "            #print(\"pred:\", pred, \", gt:\", gt)\n",
    "            correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "            epoch_losses.append(loss.item())\n",
    "        accuracy = (correct.item()/len(val_loader.dataset))\n",
    "        val_accuracies.append(accuracy)    \n",
    "        avg_loss = np.mean(epoch_losses)    \n",
    "        val_losses.append(avg_loss)\n",
    "        print(\"Validation: loss:\", avg_loss, \", accuracy:\", accuracy)\n",
    "        if avg_loss < min_loss:\n",
    "            torch.save(model, best_path)\n",
    "            min_loss = avg_loss\n",
    "            print(\"New min loss:\", min_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot losses vs epoch \n",
    "plt.figure(1)  \n",
    "plt.plot(np.arange(1,301), tr_losses, np.arange(1,301), val_losses)\n",
    "plt.title(\"Loss vs Epoch with SGD\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "# plot losses vs epoch \n",
    "plt.figure(2)  \n",
    "plt.plot(np.arange(1,301), tr_accuracies, np.arange(1,301), val_accuracies)\n",
    "plt.title(\"Accuracy vs Epoch with SGD\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGlkTe9e-VLO"
   },
   "source": [
    "####Test with SGD [10 pts.]\n",
    "\n",
    "Report the following for your best model on your test set which has not been seen by the model yet.\n",
    "1. A heatmap for confusion matrix\n",
    "2. Accuracy\n",
    "3. Macro Precision\n",
    "4. Macro Recall\n",
    "5. F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LNc_qjAECN9V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: 0.991862214654684 \n",
      "Mean Acc: 0.7435 \n",
      "Mean Macro Precision: 0.7440082905117317 \n",
      "Mean Macro Recall: 0.7395644985304424 \n",
      "Mean Macro F1 Score: 0.7417797392065252\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test CNN\n",
    "# load best model\n",
    "best_path = \"best_cnn_sgd.pth\"\n",
    "model = torch.load(best_path).to(device)\n",
    "\n",
    "#evaluate on test set\n",
    "model = model.eval()\n",
    "predictions = []\n",
    "ground_truths=[]\n",
    "losses = []\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        losses.append(loss.item())\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1].cpu()\n",
    "        gt = y_batch.data.max(1, keepdim=True)[1].cpu()\n",
    "        correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "        pred = pred.reshape(len(pred))\n",
    "        gt = gt.reshape(len(gt))\n",
    "        predictions = np.concatenate((predictions, pred))\n",
    "        ground_truths = np.concatenate((ground_truths, gt))\n",
    "avg_loss = np.mean(losses)    \n",
    "accuracy = (correct.item()/len(test_loader.dataset))\n",
    "conf_matrix = confusion_matrix(predictions, ground_truths)  \n",
    "#   calculate precision\n",
    "p_0 = conf_matrix[0,0]/np.sum(conf_matrix[0,:])\n",
    "p_1 = conf_matrix[1,1]/np.sum(conf_matrix[1,:])\n",
    "p_2 = conf_matrix[2,2]/np.sum(conf_matrix[2,:])\n",
    "p_3 = conf_matrix[3,3]/np.sum(conf_matrix[3,:])\n",
    "mean_precision = (p_0 + p_1 + p_2 + p_3)/4\n",
    "#   calculate recall\n",
    "r_0 = conf_matrix[0,0]/np.sum(conf_matrix[:,0])\n",
    "r_1 = conf_matrix[1,1]/np.sum(conf_matrix[:,1])\n",
    "r_2 = conf_matrix[2,2]/np.sum(conf_matrix[:,2])\n",
    "r_3 = conf_matrix[3,3]/np.sum(conf_matrix[:,3])\n",
    "mean_recall = (r_0 + r_1 + r_2 + r_3)/4\n",
    "#   calculate F1 score\n",
    "f1 = (2*mean_precision*mean_recall)/(mean_precision+mean_recall)\n",
    "\n",
    "# print metrics\n",
    "print(\"Mean Loss:\", avg_loss, \"\\nMean Acc:\", accuracy, \"\\nMean Macro Precision:\", mean_precision, \"\\nMean Macro Recall:\", mean_recall, \"\\nMean Macro F1 Score:\", f1) \n",
    "\n",
    "# plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_matrix)\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(4))\n",
    "ax.set_yticks(np.arange(4))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3L2zjEN_tZf"
   },
   "source": [
    "###Adam Optimizer [25 pts.]\n",
    "\n",
    "Adam is an adaptive learning rate optimization algorithm that has been designed specifically for training deep neural networks. It was presented by Diederik Kingma from OpenAI and Jimmy Ba from the University of Toronto in their 2015 ICLR paper (poster) titled “Adam: A Method for Stochastic Optimization“.\n",
    "\n",
    "Nowadays, most of machine learning frameworks, including tensorflow, Pytorch, and Keras, choose Adam as the default optimizer. In this question, you will experiment with it and try to understand why it replaced SGD as the default optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOQ75RHP-Fdn"
   },
   "source": [
    "####Training with ADAM [15 pts.]\n",
    "\n",
    "Train your model up to 300 epochs with properly processed inputs, i.e. call your \"get_dataset\". This time use Adam Optimizer as your optimizer. Tune your learning rate, weight decay. Save your best model as \"best_cnn_adam.pth\". The best model should be selected based on validation dataset. You could use any measurement and/or metric to decide on the best model for each network. However, you must explain your reasoning in your choice.\n",
    "\n",
    "During training, you need to plot:\n",
    "1. training loss and validation loss vs. epoch\n",
    "2. training accuracy and validation accuracy vs. epoch <br>\n",
    "\n",
    "Name your axes and plots properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3fr4WUpQCO5s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) Training: loss: 1.383372471549294 , accuracy: 0.31314285714285717\n",
      "Validation: loss: 1.372331514954567 , accuracy: 0.454\n",
      "New min loss: 1.372331514954567\n",
      "2 ) Training: loss: 1.316089601950212 , accuracy: 0.47885714285714287\n",
      "Validation: loss: 1.2415637224912643 , accuracy: 0.545\n",
      "New min loss: 1.2415637224912643\n",
      "3 ) Training: loss: 1.1961022810502486 , accuracy: 0.5577142857142857\n",
      "Validation: loss: 1.1728492081165314 , accuracy: 0.567\n",
      "New min loss: 1.1728492081165314\n",
      "4 ) Training: loss: 1.1537523052909158 , accuracy: 0.5845714285714285\n",
      "Validation: loss: 1.1469388455152512 , accuracy: 0.604\n",
      "New min loss: 1.1469388455152512\n",
      "5 ) Training: loss: 1.1306741085919467 , accuracy: 0.6062857142857143\n",
      "Validation: loss: 1.1280535459518433 , accuracy: 0.61\n",
      "New min loss: 1.1280535459518433\n",
      "6 ) Training: loss: 1.1153248505158857 , accuracy: 0.6227142857142857\n",
      "Validation: loss: 1.1140808165073395 , accuracy: 0.628\n",
      "New min loss: 1.1140808165073395\n",
      "7 ) Training: loss: 1.1036024592139504 , accuracy: 0.6361428571428571\n",
      "Validation: loss: 1.1032752096652985 , accuracy: 0.637\n",
      "New min loss: 1.1032752096652985\n",
      "8 ) Training: loss: 1.094797641580755 , accuracy: 0.6465714285714286\n",
      "Validation: loss: 1.0956677347421646 , accuracy: 0.648\n",
      "New min loss: 1.0956677347421646\n",
      "9 ) Training: loss: 1.0881693428212946 , accuracy: 0.6528571428571428\n",
      "Validation: loss: 1.0900580883026123 , accuracy: 0.654\n",
      "New min loss: 1.0900580883026123\n",
      "10 ) Training: loss: 1.082709806615656 , accuracy: 0.6564285714285715\n",
      "Validation: loss: 1.0850103795528412 , accuracy: 0.659\n",
      "New min loss: 1.0850103795528412\n",
      "11 ) Training: loss: 1.0777428236874667 , accuracy: 0.6605714285714286\n",
      "Validation: loss: 1.0806711316108704 , accuracy: 0.662\n",
      "New min loss: 1.0806711316108704\n",
      "12 ) Training: loss: 1.0734354777769608 , accuracy: 0.6664285714285715\n",
      "Validation: loss: 1.0770044922828674 , accuracy: 0.661\n",
      "New min loss: 1.0770044922828674\n",
      "13 ) Training: loss: 1.069452504678206 , accuracy: 0.672\n",
      "Validation: loss: 1.0735790431499481 , accuracy: 0.665\n",
      "New min loss: 1.0735790431499481\n",
      "14 ) Training: loss: 1.0656537207690153 , accuracy: 0.6754285714285714\n",
      "Validation: loss: 1.0702678561210632 , accuracy: 0.668\n",
      "New min loss: 1.0702678561210632\n",
      "15 ) Training: loss: 1.061971488865939 , accuracy: 0.6785714285714286\n",
      "Validation: loss: 1.0669979751110077 , accuracy: 0.673\n",
      "New min loss: 1.0669979751110077\n",
      "16 ) Training: loss: 1.0583742726932872 , accuracy: 0.6814285714285714\n",
      "Validation: loss: 1.0637146085500717 , accuracy: 0.676\n",
      "New min loss: 1.0637146085500717\n",
      "17 ) Training: loss: 1.0548431147228587 , accuracy: 0.6867142857142857\n",
      "Validation: loss: 1.060430869460106 , accuracy: 0.678\n",
      "New min loss: 1.060430869460106\n",
      "18 ) Training: loss: 1.051377341964028 , accuracy: 0.6887142857142857\n",
      "Validation: loss: 1.0572239756584167 , accuracy: 0.681\n",
      "New min loss: 1.0572239756584167\n",
      "19 ) Training: loss: 1.047974122654308 , accuracy: 0.6931428571428572\n",
      "Validation: loss: 1.054091826081276 , accuracy: 0.685\n",
      "New min loss: 1.054091826081276\n",
      "20 ) Training: loss: 1.0446395321325823 , accuracy: 0.6972857142857143\n",
      "Validation: loss: 1.0511047393083572 , accuracy: 0.687\n",
      "New min loss: 1.0511047393083572\n",
      "21 ) Training: loss: 1.0413583007725802 , accuracy: 0.7024285714285714\n",
      "Validation: loss: 1.0482217818498611 , accuracy: 0.695\n",
      "New min loss: 1.0482217818498611\n",
      "22 ) Training: loss: 1.0381775758483194 , accuracy: 0.7062857142857143\n",
      "Validation: loss: 1.0454557538032532 , accuracy: 0.697\n",
      "New min loss: 1.0454557538032532\n",
      "23 ) Training: loss: 1.0351935451680965 , accuracy: 0.71\n",
      "Validation: loss: 1.0428407937288284 , accuracy: 0.698\n",
      "New min loss: 1.0428407937288284\n",
      "24 ) Training: loss: 1.0324605280702763 , accuracy: 0.7124285714285714\n",
      "Validation: loss: 1.0404474288225174 , accuracy: 0.702\n",
      "New min loss: 1.0404474288225174\n",
      "25 ) Training: loss: 1.0299329974434592 , accuracy: 0.714\n",
      "Validation: loss: 1.038386881351471 , accuracy: 0.705\n",
      "New min loss: 1.038386881351471\n",
      "26 ) Training: loss: 1.0277289759029042 , accuracy: 0.7174285714285714\n",
      "Validation: loss: 1.0363254249095917 , accuracy: 0.708\n",
      "New min loss: 1.0363254249095917\n",
      "27 ) Training: loss: 1.0256685668771917 , accuracy: 0.7188571428571429\n",
      "Validation: loss: 1.0345231741666794 , accuracy: 0.71\n",
      "New min loss: 1.0345231741666794\n",
      "28 ) Training: loss: 1.0237373915585604 , accuracy: 0.721\n",
      "Validation: loss: 1.0327907353639603 , accuracy: 0.713\n",
      "New min loss: 1.0327907353639603\n",
      "29 ) Training: loss: 1.0218897212635387 , accuracy: 0.7224285714285714\n",
      "Validation: loss: 1.0311319380998611 , accuracy: 0.716\n",
      "New min loss: 1.0311319380998611\n",
      "30 ) Training: loss: 1.0201132741841403 , accuracy: 0.7242857142857143\n",
      "Validation: loss: 1.029530018568039 , accuracy: 0.717\n",
      "New min loss: 1.029530018568039\n",
      "31 ) Training: loss: 1.018380757895383 , accuracy: 0.7267142857142858\n",
      "Validation: loss: 1.0279646664857864 , accuracy: 0.722\n",
      "New min loss: 1.0279646664857864\n",
      "32 ) Training: loss: 1.0166733969341626 , accuracy: 0.7288571428571429\n",
      "Validation: loss: 1.0264219790697098 , accuracy: 0.726\n",
      "New min loss: 1.0264219790697098\n",
      "33 ) Training: loss: 1.0149800463156267 , accuracy: 0.7304285714285714\n",
      "Validation: loss: 1.0248954370617867 , accuracy: 0.727\n",
      "New min loss: 1.0248954370617867\n",
      "34 ) Training: loss: 1.013299076123671 , accuracy: 0.7317142857142858\n",
      "Validation: loss: 1.0234071388840675 , accuracy: 0.728\n",
      "New min loss: 1.0234071388840675\n",
      "35 ) Training: loss: 1.0116449670358139 , accuracy: 0.7342857142857143\n",
      "Validation: loss: 1.0219662860035896 , accuracy: 0.729\n",
      "New min loss: 1.0219662860035896\n",
      "36 ) Training: loss: 1.0100289669903841 , accuracy: 0.7357142857142858\n",
      "Validation: loss: 1.0205702930688858 , accuracy: 0.73\n",
      "New min loss: 1.0205702930688858\n",
      "37 ) Training: loss: 1.0084456205368042 , accuracy: 0.7382857142857143\n",
      "Validation: loss: 1.0192312821745872 , accuracy: 0.73\n",
      "New min loss: 1.0192312821745872\n",
      "38 ) Training: loss: 1.0068989764560352 , accuracy: 0.7407142857142858\n",
      "Validation: loss: 1.017938181757927 , accuracy: 0.731\n",
      "New min loss: 1.017938181757927\n",
      "39 ) Training: loss: 1.0053885785016146 , accuracy: 0.7415714285714285\n",
      "Validation: loss: 1.0166960507631302 , accuracy: 0.73\n",
      "New min loss: 1.0166960507631302\n",
      "40 ) Training: loss: 1.0039181124080312 , accuracy: 0.744\n",
      "Validation: loss: 1.0155003145337105 , accuracy: 0.731\n",
      "New min loss: 1.0155003145337105\n",
      "41 ) Training: loss: 1.0024923985654657 , accuracy: 0.7457142857142857\n",
      "Validation: loss: 1.0143459662795067 , accuracy: 0.733\n",
      "New min loss: 1.0143459662795067\n",
      "42 ) Training: loss: 1.001102486523715 , accuracy: 0.7468571428571429\n",
      "Validation: loss: 1.0132364854216576 , accuracy: 0.731\n",
      "New min loss: 1.0132364854216576\n",
      "43 ) Training: loss: 0.999748543175784 , accuracy: 0.7478571428571429\n",
      "Validation: loss: 1.012182466685772 , accuracy: 0.731\n",
      "New min loss: 1.012182466685772\n",
      "44 ) Training: loss: 0.9984350236979398 , accuracy: 0.7497142857142857\n",
      "Validation: loss: 1.011180967092514 , accuracy: 0.732\n",
      "New min loss: 1.011180967092514\n",
      "45 ) Training: loss: 0.9971558625047857 , accuracy: 0.7517142857142857\n",
      "Validation: loss: 1.0102145075798035 , accuracy: 0.734\n",
      "New min loss: 1.0102145075798035\n",
      "46 ) Training: loss: 0.9959091457453642 , accuracy: 0.7528571428571429\n",
      "Validation: loss: 1.0092823952436447 , accuracy: 0.735\n",
      "New min loss: 1.0092823952436447\n",
      "47 ) Training: loss: 0.9946885531598871 , accuracy: 0.7531428571428571\n",
      "Validation: loss: 1.0083671137690544 , accuracy: 0.737\n",
      "New min loss: 1.0083671137690544\n",
      "48 ) Training: loss: 0.9934999769384211 , accuracy: 0.7542857142857143\n",
      "Validation: loss: 1.007464475929737 , accuracy: 0.737\n",
      "New min loss: 1.007464475929737\n",
      "49 ) Training: loss: 0.9923368529839949 , accuracy: 0.7555714285714286\n",
      "Validation: loss: 1.0065691769123077 , accuracy: 0.737\n",
      "New min loss: 1.0065691769123077\n",
      "50 ) Training: loss: 0.99120539968664 , accuracy: 0.7562857142857143\n",
      "Validation: loss: 1.0057002678513527 , accuracy: 0.738\n",
      "New min loss: 1.0057002678513527\n",
      "51 ) Training: loss: 0.9900976332751188 , accuracy: 0.7578571428571429\n",
      "Validation: loss: 1.00486508756876 , accuracy: 0.74\n",
      "New min loss: 1.00486508756876\n",
      "52 ) Training: loss: 0.9890167106281628 , accuracy: 0.7592857142857142\n",
      "Validation: loss: 1.004047431051731 , accuracy: 0.74\n",
      "New min loss: 1.004047431051731\n",
      "53 ) Training: loss: 0.9879606106064537 , accuracy: 0.7602857142857142\n",
      "Validation: loss: 1.0032567381858826 , accuracy: 0.741\n",
      "New min loss: 1.0032567381858826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 ) Training: loss: 0.9869303627447649 , accuracy: 0.7611428571428571\n",
      "Validation: loss: 1.0024849623441696 , accuracy: 0.742\n",
      "New min loss: 1.0024849623441696\n",
      "55 ) Training: loss: 0.9859269055453214 , accuracy: 0.7618571428571429\n",
      "Validation: loss: 1.0017372816801071 , accuracy: 0.742\n",
      "New min loss: 1.0017372816801071\n",
      "56 ) Training: loss: 0.9849431590600447 , accuracy: 0.762\n",
      "Validation: loss: 1.001023307442665 , accuracy: 0.742\n",
      "New min loss: 1.001023307442665\n",
      "57 ) Training: loss: 0.9839773318984292 , accuracy: 0.7627142857142857\n",
      "Validation: loss: 1.0003342181444168 , accuracy: 0.742\n",
      "New min loss: 1.0003342181444168\n",
      "58 ) Training: loss: 0.9830341111529958 , accuracy: 0.7638571428571429\n",
      "Validation: loss: 0.9996531680226326 , accuracy: 0.742\n",
      "New min loss: 0.9996531680226326\n",
      "59 ) Training: loss: 0.982101414420388 , accuracy: 0.7648571428571429\n",
      "Validation: loss: 0.9989838749170303 , accuracy: 0.742\n",
      "New min loss: 0.9989838749170303\n",
      "60 ) Training: loss: 0.9811853733929721 , accuracy: 0.7662857142857142\n",
      "Validation: loss: 0.9983305335044861 , accuracy: 0.741\n",
      "New min loss: 0.9983305335044861\n",
      "61 ) Training: loss: 0.9802866729823025 , accuracy: 0.7661428571428571\n",
      "Validation: loss: 0.9976927638053894 , accuracy: 0.742\n",
      "New min loss: 0.9976927638053894\n",
      "62 ) Training: loss: 0.9793997981331565 , accuracy: 0.7668571428571429\n",
      "Validation: loss: 0.9970522075891495 , accuracy: 0.741\n",
      "New min loss: 0.9970522075891495\n",
      "63 ) Training: loss: 0.9785271427848122 , accuracy: 0.7681428571428571\n",
      "Validation: loss: 0.9964406490325928 , accuracy: 0.744\n",
      "New min loss: 0.9964406490325928\n",
      "64 ) Training: loss: 0.9776726495135915 , accuracy: 0.7692857142857142\n",
      "Validation: loss: 0.9958358108997345 , accuracy: 0.745\n",
      "New min loss: 0.9958358108997345\n",
      "65 ) Training: loss: 0.9768342895941301 , accuracy: 0.7711428571428571\n",
      "Validation: loss: 0.995205320417881 , accuracy: 0.747\n",
      "New min loss: 0.995205320417881\n",
      "66 ) Training: loss: 0.9760062434456566 , accuracy: 0.7725714285714286\n",
      "Validation: loss: 0.9945562928915024 , accuracy: 0.747\n",
      "New min loss: 0.9945562928915024\n",
      "67 ) Training: loss: 0.9751906925981695 , accuracy: 0.7737142857142857\n",
      "Validation: loss: 0.9938874468207359 , accuracy: 0.748\n",
      "New min loss: 0.9938874468207359\n",
      "68 ) Training: loss: 0.9743983322923834 , accuracy: 0.7745714285714286\n",
      "Validation: loss: 0.9932021871209145 , accuracy: 0.749\n",
      "New min loss: 0.9932021871209145\n",
      "69 ) Training: loss: 0.9736225800080733 , accuracy: 0.7761428571428571\n",
      "Validation: loss: 0.9925615265965462 , accuracy: 0.749\n",
      "New min loss: 0.9925615265965462\n",
      "70 ) Training: loss: 0.9728756872090426 , accuracy: 0.7765714285714286\n",
      "Validation: loss: 0.9919797331094742 , accuracy: 0.749\n",
      "New min loss: 0.9919797331094742\n",
      "71 ) Training: loss: 0.9721553347327493 , accuracy: 0.7774285714285715\n",
      "Validation: loss: 0.9914311841130257 , accuracy: 0.749\n",
      "New min loss: 0.9914311841130257\n",
      "72 ) Training: loss: 0.9714569926261902 , accuracy: 0.7778571428571428\n",
      "Validation: loss: 0.9909244030714035 , accuracy: 0.749\n",
      "New min loss: 0.9909244030714035\n",
      "73 ) Training: loss: 0.9707795630801808 , accuracy: 0.7782857142857142\n",
      "Validation: loss: 0.9904312416911125 , accuracy: 0.749\n",
      "New min loss: 0.9904312416911125\n",
      "74 ) Training: loss: 0.9701142560351979 , accuracy: 0.7787142857142857\n",
      "Validation: loss: 0.9899617359042168 , accuracy: 0.749\n",
      "New min loss: 0.9899617359042168\n",
      "75 ) Training: loss: 0.969461587342349 , accuracy: 0.7802857142857142\n",
      "Validation: loss: 0.9895113110542297 , accuracy: 0.75\n",
      "New min loss: 0.9895113110542297\n",
      "76 ) Training: loss: 0.9688208341598511 , accuracy: 0.7821428571428571\n",
      "Validation: loss: 0.989078663289547 , accuracy: 0.751\n",
      "New min loss: 0.989078663289547\n",
      "77 ) Training: loss: 0.9681932351805947 , accuracy: 0.7825714285714286\n",
      "Validation: loss: 0.9886521026492119 , accuracy: 0.753\n",
      "New min loss: 0.9886521026492119\n",
      "78 ) Training: loss: 0.9675759803165089 , accuracy: 0.783\n",
      "Validation: loss: 0.988231398165226 , accuracy: 0.751\n",
      "New min loss: 0.988231398165226\n",
      "79 ) Training: loss: 0.9669692462140863 , accuracy: 0.7837142857142857\n",
      "Validation: loss: 0.9878288805484772 , accuracy: 0.751\n",
      "New min loss: 0.9878288805484772\n",
      "80 ) Training: loss: 0.9663717194037004 , accuracy: 0.7841428571428571\n",
      "Validation: loss: 0.9874353036284447 , accuracy: 0.752\n",
      "New min loss: 0.9874353036284447\n",
      "81 ) Training: loss: 0.9657843687317588 , accuracy: 0.7838571428571428\n",
      "Validation: loss: 0.9870480895042419 , accuracy: 0.752\n",
      "New min loss: 0.9870480895042419\n",
      "82 ) Training: loss: 0.9652052749286998 , accuracy: 0.784\n",
      "Validation: loss: 0.9866713061928749 , accuracy: 0.751\n",
      "New min loss: 0.9866713061928749\n",
      "83 ) Training: loss: 0.9646331277760593 , accuracy: 0.7848571428571428\n",
      "Validation: loss: 0.9863000512123108 , accuracy: 0.75\n",
      "New min loss: 0.9863000512123108\n",
      "84 ) Training: loss: 0.9640691226178949 , accuracy: 0.785\n",
      "Validation: loss: 0.9859364479780197 , accuracy: 0.75\n",
      "New min loss: 0.9859364479780197\n",
      "85 ) Training: loss: 0.9635143507610667 , accuracy: 0.7854285714285715\n",
      "Validation: loss: 0.9855807051062584 , accuracy: 0.751\n",
      "New min loss: 0.9855807051062584\n",
      "86 ) Training: loss: 0.9629664160988548 , accuracy: 0.7862857142857143\n",
      "Validation: loss: 0.9852317720651627 , accuracy: 0.752\n",
      "New min loss: 0.9852317720651627\n",
      "87 ) Training: loss: 0.962424868887121 , accuracy: 0.787\n",
      "Validation: loss: 0.9848851785063744 , accuracy: 0.752\n",
      "New min loss: 0.9848851785063744\n",
      "88 ) Training: loss: 0.9618884487585588 , accuracy: 0.7872857142857143\n",
      "Validation: loss: 0.9845449477434158 , accuracy: 0.752\n",
      "New min loss: 0.9845449477434158\n",
      "89 ) Training: loss: 0.9613579598340121 , accuracy: 0.788\n",
      "Validation: loss: 0.984209381043911 , accuracy: 0.752\n",
      "New min loss: 0.984209381043911\n",
      "90 ) Training: loss: 0.9608328754251654 , accuracy: 0.7884285714285715\n",
      "Validation: loss: 0.9838802218437195 , accuracy: 0.753\n",
      "New min loss: 0.9838802218437195\n",
      "91 ) Training: loss: 0.9603118788112294 , accuracy: 0.7894285714285715\n",
      "Validation: loss: 0.9835587963461876 , accuracy: 0.753\n",
      "New min loss: 0.9835587963461876\n",
      "92 ) Training: loss: 0.9597968524152583 , accuracy: 0.7901428571428571\n",
      "Validation: loss: 0.9832391813397408 , accuracy: 0.753\n",
      "New min loss: 0.9832391813397408\n",
      "93 ) Training: loss: 0.9592877236279574 , accuracy: 0.7907142857142857\n",
      "Validation: loss: 0.9829327091574669 , accuracy: 0.752\n",
      "New min loss: 0.9829327091574669\n",
      "94 ) Training: loss: 0.9587846463376826 , accuracy: 0.7912857142857143\n",
      "Validation: loss: 0.9826227053999901 , accuracy: 0.753\n",
      "New min loss: 0.9826227053999901\n",
      "95 ) Training: loss: 0.9582841266285289 , accuracy: 0.7922857142857143\n",
      "Validation: loss: 0.9823225438594818 , accuracy: 0.752\n",
      "New min loss: 0.9823225438594818\n",
      "96 ) Training: loss: 0.9577880881049416 , accuracy: 0.7928571428571428\n",
      "Validation: loss: 0.9820254147052765 , accuracy: 0.752\n",
      "New min loss: 0.9820254147052765\n",
      "97 ) Training: loss: 0.9572946927764199 , accuracy: 0.794\n",
      "Validation: loss: 0.9817299544811249 , accuracy: 0.753\n",
      "New min loss: 0.9817299544811249\n",
      "98 ) Training: loss: 0.9568046277219598 , accuracy: 0.7951428571428572\n",
      "Validation: loss: 0.981436662375927 , accuracy: 0.754\n",
      "New min loss: 0.981436662375927\n",
      "99 ) Training: loss: 0.9563192866065285 , accuracy: 0.7957142857142857\n",
      "Validation: loss: 0.9811494201421738 , accuracy: 0.755\n",
      "New min loss: 0.9811494201421738\n",
      "100 ) Training: loss: 0.9558387496254661 , accuracy: 0.7964285714285714\n",
      "Validation: loss: 0.9808717891573906 , accuracy: 0.756\n",
      "New min loss: 0.9808717891573906\n",
      "101 ) Training: loss: 0.9553616946393794 , accuracy: 0.7975714285714286\n",
      "Validation: loss: 0.9805971533060074 , accuracy: 0.757\n",
      "New min loss: 0.9805971533060074\n",
      "102 ) Training: loss: 0.9548866748809814 , accuracy: 0.7981428571428572\n",
      "Validation: loss: 0.9803236350417137 , accuracy: 0.757\n",
      "New min loss: 0.9803236350417137\n",
      "103 ) Training: loss: 0.9544153289361433 , accuracy: 0.7982857142857143\n",
      "Validation: loss: 0.9800539240241051 , accuracy: 0.758\n",
      "New min loss: 0.9800539240241051\n",
      "104 ) Training: loss: 0.9539466023445129 , accuracy: 0.7984285714285714\n",
      "Validation: loss: 0.9797886237502098 , accuracy: 0.758\n",
      "New min loss: 0.9797886237502098\n",
      "105 ) Training: loss: 0.9534803379665722 , accuracy: 0.7985714285714286\n",
      "Validation: loss: 0.9795315265655518 , accuracy: 0.759\n",
      "New min loss: 0.9795315265655518\n",
      "106 ) Training: loss: 0.9530177235603332 , accuracy: 0.7994285714285714\n",
      "Validation: loss: 0.9792859703302383 , accuracy: 0.759\n",
      "New min loss: 0.9792859703302383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 ) Training: loss: 0.9525607174093073 , accuracy: 0.7998571428571428\n",
      "Validation: loss: 0.9790419712662697 , accuracy: 0.759\n",
      "New min loss: 0.9790419712662697\n",
      "108 ) Training: loss: 0.952106016332453 , accuracy: 0.8007142857142857\n",
      "Validation: loss: 0.9787957966327667 , accuracy: 0.759\n",
      "New min loss: 0.9787957966327667\n",
      "109 ) Training: loss: 0.9516543886878274 , accuracy: 0.8011428571428572\n",
      "Validation: loss: 0.9785592183470726 , accuracy: 0.759\n",
      "New min loss: 0.9785592183470726\n",
      "110 ) Training: loss: 0.9512063123963096 , accuracy: 0.8012857142857143\n",
      "Validation: loss: 0.9783214628696442 , accuracy: 0.759\n",
      "New min loss: 0.9783214628696442\n",
      "111 ) Training: loss: 0.9507572271607139 , accuracy: 0.8022857142857143\n",
      "Validation: loss: 0.9780960157513618 , accuracy: 0.759\n",
      "New min loss: 0.9780960157513618\n",
      "112 ) Training: loss: 0.950312864780426 , accuracy: 0.8031428571428572\n",
      "Validation: loss: 0.9778709262609482 , accuracy: 0.761\n",
      "New min loss: 0.9778709262609482\n",
      "113 ) Training: loss: 0.9498731710694053 , accuracy: 0.8035714285714286\n",
      "Validation: loss: 0.9776495322585106 , accuracy: 0.762\n",
      "New min loss: 0.9776495322585106\n",
      "114 ) Training: loss: 0.9494362744418058 , accuracy: 0.8038571428571428\n",
      "Validation: loss: 0.9774345234036446 , accuracy: 0.762\n",
      "New min loss: 0.9774345234036446\n",
      "115 ) Training: loss: 0.9490020957860079 , accuracy: 0.8044285714285714\n",
      "Validation: loss: 0.9772198274731636 , accuracy: 0.764\n",
      "New min loss: 0.9772198274731636\n",
      "116 ) Training: loss: 0.9485727028413252 , accuracy: 0.8045714285714286\n",
      "Validation: loss: 0.9770152121782303 , accuracy: 0.764\n",
      "New min loss: 0.9770152121782303\n",
      "117 ) Training: loss: 0.9481411196968772 , accuracy: 0.8047142857142857\n",
      "Validation: loss: 0.9768095016479492 , accuracy: 0.763\n",
      "New min loss: 0.9768095016479492\n",
      "118 ) Training: loss: 0.9477140480821783 , accuracy: 0.805\n",
      "Validation: loss: 0.9766090214252472 , accuracy: 0.763\n",
      "New min loss: 0.9766090214252472\n",
      "119 ) Training: loss: 0.9472879908301614 , accuracy: 0.8052857142857143\n",
      "Validation: loss: 0.9764122515916824 , accuracy: 0.763\n",
      "New min loss: 0.9764122515916824\n",
      "120 ) Training: loss: 0.946866675940427 , accuracy: 0.8055714285714286\n",
      "Validation: loss: 0.9762190133333206 , accuracy: 0.763\n",
      "New min loss: 0.9762190133333206\n",
      "121 ) Training: loss: 0.9464476628737016 , accuracy: 0.8061428571428572\n",
      "Validation: loss: 0.9760289117693901 , accuracy: 0.763\n",
      "New min loss: 0.9760289117693901\n",
      "122 ) Training: loss: 0.9460317362438548 , accuracy: 0.8062857142857143\n",
      "Validation: loss: 0.975846104323864 , accuracy: 0.761\n",
      "New min loss: 0.975846104323864\n",
      "123 ) Training: loss: 0.9456172834743153 , accuracy: 0.8064285714285714\n",
      "Validation: loss: 0.9756589978933334 , accuracy: 0.761\n",
      "New min loss: 0.9756589978933334\n",
      "124 ) Training: loss: 0.9452023928815668 , accuracy: 0.807\n",
      "Validation: loss: 0.9754822254180908 , accuracy: 0.76\n",
      "New min loss: 0.9754822254180908\n",
      "125 ) Training: loss: 0.944795421036807 , accuracy: 0.8075714285714286\n",
      "Validation: loss: 0.9753102138638496 , accuracy: 0.76\n",
      "New min loss: 0.9753102138638496\n",
      "126 ) Training: loss: 0.9443876450712031 , accuracy: 0.8078571428571428\n",
      "Validation: loss: 0.975136436522007 , accuracy: 0.76\n",
      "New min loss: 0.975136436522007\n",
      "127 ) Training: loss: 0.9439816821705211 , accuracy: 0.8081428571428572\n",
      "Validation: loss: 0.9749742820858955 , accuracy: 0.76\n",
      "New min loss: 0.9749742820858955\n",
      "128 ) Training: loss: 0.9435771974650297 , accuracy: 0.809\n",
      "Validation: loss: 0.9748152941465378 , accuracy: 0.76\n",
      "New min loss: 0.9748152941465378\n",
      "129 ) Training: loss: 0.9431745236570185 , accuracy: 0.8092857142857143\n",
      "Validation: loss: 0.9746596142649651 , accuracy: 0.76\n",
      "New min loss: 0.9746596142649651\n",
      "130 ) Training: loss: 0.9427735751325433 , accuracy: 0.8095714285714286\n",
      "Validation: loss: 0.9745074212551117 , accuracy: 0.762\n",
      "New min loss: 0.9745074212551117\n",
      "131 ) Training: loss: 0.9423779173330827 , accuracy: 0.8097142857142857\n",
      "Validation: loss: 0.9743589833378792 , accuracy: 0.762\n",
      "New min loss: 0.9743589833378792\n",
      "132 ) Training: loss: 0.941983023556796 , accuracy: 0.8101428571428572\n",
      "Validation: loss: 0.974209800362587 , accuracy: 0.762\n",
      "New min loss: 0.974209800362587\n",
      "133 ) Training: loss: 0.9415901910174976 , accuracy: 0.8107142857142857\n",
      "Validation: loss: 0.9740637764334679 , accuracy: 0.762\n",
      "New min loss: 0.9740637764334679\n",
      "134 ) Training: loss: 0.9411986416036432 , accuracy: 0.811\n",
      "Validation: loss: 0.97391776740551 , accuracy: 0.761\n",
      "New min loss: 0.97391776740551\n",
      "135 ) Training: loss: 0.940807370706038 , accuracy: 0.812\n",
      "Validation: loss: 0.9737749025225639 , accuracy: 0.762\n",
      "New min loss: 0.9737749025225639\n",
      "136 ) Training: loss: 0.9404192696918141 , accuracy: 0.812\n",
      "Validation: loss: 0.973636694252491 , accuracy: 0.762\n",
      "New min loss: 0.973636694252491\n",
      "137 ) Training: loss: 0.9400340817191384 , accuracy: 0.8127142857142857\n",
      "Validation: loss: 0.9734948202967644 , accuracy: 0.765\n",
      "New min loss: 0.9734948202967644\n",
      "138 ) Training: loss: 0.9396499969742514 , accuracy: 0.813\n",
      "Validation: loss: 0.9733608439564705 , accuracy: 0.765\n",
      "New min loss: 0.9733608439564705\n",
      "139 ) Training: loss: 0.9392680872570385 , accuracy: 0.8137142857142857\n",
      "Validation: loss: 0.9732295051217079 , accuracy: 0.765\n",
      "New min loss: 0.9732295051217079\n",
      "140 ) Training: loss: 0.9388904885812239 , accuracy: 0.8141428571428572\n",
      "Validation: loss: 0.9730959609150887 , accuracy: 0.763\n",
      "New min loss: 0.9730959609150887\n",
      "141 ) Training: loss: 0.9385139172727411 , accuracy: 0.8145714285714286\n",
      "Validation: loss: 0.9729613661766052 , accuracy: 0.763\n",
      "New min loss: 0.9729613661766052\n",
      "142 ) Training: loss: 0.938139207796617 , accuracy: 0.815\n",
      "Validation: loss: 0.972835011780262 , accuracy: 0.763\n",
      "New min loss: 0.972835011780262\n",
      "143 ) Training: loss: 0.9377659700133584 , accuracy: 0.8157142857142857\n",
      "Validation: loss: 0.9727109596133232 , accuracy: 0.764\n",
      "New min loss: 0.9727109596133232\n",
      "144 ) Training: loss: 0.9373942212624984 , accuracy: 0.816\n",
      "Validation: loss: 0.9725880771875381 , accuracy: 0.764\n",
      "New min loss: 0.9725880771875381\n",
      "145 ) Training: loss: 0.9370228897441517 , accuracy: 0.8161428571428572\n",
      "Validation: loss: 0.9724687039852142 , accuracy: 0.764\n",
      "New min loss: 0.9724687039852142\n",
      "146 ) Training: loss: 0.9366539868441495 , accuracy: 0.8162857142857143\n",
      "Validation: loss: 0.9723455756902695 , accuracy: 0.764\n",
      "New min loss: 0.9723455756902695\n",
      "147 ) Training: loss: 0.9362870400602167 , accuracy: 0.817\n",
      "Validation: loss: 0.9722287952899933 , accuracy: 0.764\n",
      "New min loss: 0.9722287952899933\n",
      "148 ) Training: loss: 0.9359218803319064 , accuracy: 0.8177142857142857\n",
      "Validation: loss: 0.9721119850873947 , accuracy: 0.765\n",
      "New min loss: 0.9721119850873947\n",
      "149 ) Training: loss: 0.9355581099336797 , accuracy: 0.8184285714285714\n",
      "Validation: loss: 0.9719958156347275 , accuracy: 0.765\n",
      "New min loss: 0.9719958156347275\n",
      "150 ) Training: loss: 0.9351973804560575 , accuracy: 0.8191428571428572\n",
      "Validation: loss: 0.9718803465366364 , accuracy: 0.766\n",
      "New min loss: 0.9718803465366364\n",
      "151 ) Training: loss: 0.9348385875875299 , accuracy: 0.8194285714285714\n",
      "Validation: loss: 0.9717666953802109 , accuracy: 0.767\n",
      "New min loss: 0.9717666953802109\n",
      "152 ) Training: loss: 0.9344813368537209 , accuracy: 0.8195714285714286\n",
      "Validation: loss: 0.9716588631272316 , accuracy: 0.767\n",
      "New min loss: 0.9716588631272316\n",
      "153 ) Training: loss: 0.9341244654221968 , accuracy: 0.82\n",
      "Validation: loss: 0.9715515971183777 , accuracy: 0.765\n",
      "New min loss: 0.9715515971183777\n",
      "154 ) Training: loss: 0.9337685595859181 , accuracy: 0.8208571428571428\n",
      "Validation: loss: 0.9714515805244446 , accuracy: 0.765\n",
      "New min loss: 0.9714515805244446\n",
      "155 ) Training: loss: 0.933416625586423 , accuracy: 0.8212857142857143\n",
      "Validation: loss: 0.9713548347353935 , accuracy: 0.766\n",
      "New min loss: 0.9713548347353935\n",
      "156 ) Training: loss: 0.9330668687820435 , accuracy: 0.822\n",
      "Validation: loss: 0.9712601080536842 , accuracy: 0.765\n",
      "New min loss: 0.9712601080536842\n",
      "157 ) Training: loss: 0.9327188394286415 , accuracy: 0.8224285714285714\n",
      "Validation: loss: 0.9711687117815018 , accuracy: 0.766\n",
      "New min loss: 0.9711687117815018\n",
      "158 ) Training: loss: 0.9323733232238076 , accuracy: 0.8227142857142857\n",
      "Validation: loss: 0.9710793867707253 , accuracy: 0.766\n",
      "New min loss: 0.9710793867707253\n",
      "159 ) Training: loss: 0.9320304534652016 , accuracy: 0.8234285714285714\n",
      "Validation: loss: 0.9709877967834473 , accuracy: 0.765\n",
      "New min loss: 0.9709877967834473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ) Training: loss: 0.9316885980692777 , accuracy: 0.824\n",
      "Validation: loss: 0.9708954244852066 , accuracy: 0.765\n",
      "New min loss: 0.9708954244852066\n",
      "161 ) Training: loss: 0.9313471772454002 , accuracy: 0.8245714285714286\n",
      "Validation: loss: 0.970806211233139 , accuracy: 0.765\n",
      "New min loss: 0.970806211233139\n",
      "162 ) Training: loss: 0.9310096675699407 , accuracy: 0.8245714285714286\n",
      "Validation: loss: 0.9707194417715073 , accuracy: 0.765\n",
      "New min loss: 0.9707194417715073\n",
      "163 ) Training: loss: 0.9306737498803572 , accuracy: 0.8247142857142857\n",
      "Validation: loss: 0.9706321805715561 , accuracy: 0.766\n",
      "New min loss: 0.9706321805715561\n",
      "164 ) Training: loss: 0.9303383642976935 , accuracy: 0.825\n",
      "Validation: loss: 0.9705461487174034 , accuracy: 0.765\n",
      "New min loss: 0.9705461487174034\n",
      "165 ) Training: loss: 0.930004912072962 , accuracy: 0.825\n",
      "Validation: loss: 0.9704645946621895 , accuracy: 0.766\n",
      "New min loss: 0.9704645946621895\n",
      "166 ) Training: loss: 0.9296723983504556 , accuracy: 0.825\n",
      "Validation: loss: 0.9703895226120949 , accuracy: 0.766\n",
      "New min loss: 0.9703895226120949\n",
      "167 ) Training: loss: 0.9293410290371288 , accuracy: 0.8257142857142857\n",
      "Validation: loss: 0.9703098982572556 , accuracy: 0.766\n",
      "New min loss: 0.9703098982572556\n",
      "168 ) Training: loss: 0.929012616114183 , accuracy: 0.8258571428571428\n",
      "Validation: loss: 0.9702263474464417 , accuracy: 0.766\n",
      "New min loss: 0.9702263474464417\n",
      "169 ) Training: loss: 0.9286838715726679 , accuracy: 0.8261428571428572\n",
      "Validation: loss: 0.9701436087489128 , accuracy: 0.765\n",
      "New min loss: 0.9701436087489128\n",
      "170 ) Training: loss: 0.9283564209938049 , accuracy: 0.8265714285714286\n",
      "Validation: loss: 0.9700633361935616 , accuracy: 0.764\n",
      "New min loss: 0.9700633361935616\n",
      "171 ) Training: loss: 0.9280292305079374 , accuracy: 0.827\n",
      "Validation: loss: 0.9699804410338402 , accuracy: 0.764\n",
      "New min loss: 0.9699804410338402\n",
      "172 ) Training: loss: 0.9277037436311896 , accuracy: 0.8274285714285714\n",
      "Validation: loss: 0.9699017405509949 , accuracy: 0.765\n",
      "New min loss: 0.9699017405509949\n",
      "173 ) Training: loss: 0.9273791378194636 , accuracy: 0.8274285714285714\n",
      "Validation: loss: 0.9698209464550018 , accuracy: 0.765\n",
      "New min loss: 0.9698209464550018\n",
      "174 ) Training: loss: 0.9270547845146873 , accuracy: 0.8275714285714286\n",
      "Validation: loss: 0.969740092754364 , accuracy: 0.765\n",
      "New min loss: 0.969740092754364\n",
      "175 ) Training: loss: 0.9267296119169756 , accuracy: 0.828\n",
      "Validation: loss: 0.9696569219231606 , accuracy: 0.765\n",
      "New min loss: 0.9696569219231606\n",
      "176 ) Training: loss: 0.926404531435533 , accuracy: 0.829\n",
      "Validation: loss: 0.9695727527141571 , accuracy: 0.765\n",
      "New min loss: 0.9695727527141571\n",
      "177 ) Training: loss: 0.9260786522518505 , accuracy: 0.8292857142857143\n",
      "Validation: loss: 0.9694882929325104 , accuracy: 0.766\n",
      "New min loss: 0.9694882929325104\n",
      "178 ) Training: loss: 0.9257542837749828 , accuracy: 0.8298571428571428\n",
      "Validation: loss: 0.9694034531712532 , accuracy: 0.767\n",
      "New min loss: 0.9694034531712532\n",
      "179 ) Training: loss: 0.925428691777316 , accuracy: 0.83\n",
      "Validation: loss: 0.9693110659718513 , accuracy: 0.768\n",
      "New min loss: 0.9693110659718513\n",
      "180 ) Training: loss: 0.9251000025055626 , accuracy: 0.8302857142857143\n",
      "Validation: loss: 0.9692233949899673 , accuracy: 0.768\n",
      "New min loss: 0.9692233949899673\n",
      "181 ) Training: loss: 0.9247730645266447 , accuracy: 0.8308571428571428\n",
      "Validation: loss: 0.9691401720046997 , accuracy: 0.767\n",
      "New min loss: 0.9691401720046997\n",
      "182 ) Training: loss: 0.9244486115195535 , accuracy: 0.8315714285714285\n",
      "Validation: loss: 0.9690494239330292 , accuracy: 0.768\n",
      "New min loss: 0.9690494239330292\n",
      "183 ) Training: loss: 0.9241236946799538 , accuracy: 0.8321428571428572\n",
      "Validation: loss: 0.9689558520913124 , accuracy: 0.768\n",
      "New min loss: 0.9689558520913124\n",
      "184 ) Training: loss: 0.9237985361706127 , accuracy: 0.8327142857142857\n",
      "Validation: loss: 0.968865230679512 , accuracy: 0.768\n",
      "New min loss: 0.968865230679512\n",
      "185 ) Training: loss: 0.9234729192473672 , accuracy: 0.8334285714285714\n",
      "Validation: loss: 0.9687719345092773 , accuracy: 0.768\n",
      "New min loss: 0.9687719345092773\n",
      "186 ) Training: loss: 0.9231487555937333 , accuracy: 0.8342857142857143\n",
      "Validation: loss: 0.9686809927225113 , accuracy: 0.768\n",
      "New min loss: 0.9686809927225113\n",
      "187 ) Training: loss: 0.9228222045031461 , accuracy: 0.8344285714285714\n",
      "Validation: loss: 0.9685849323868752 , accuracy: 0.77\n",
      "New min loss: 0.9685849323868752\n",
      "188 ) Training: loss: 0.9224983984773809 , accuracy: 0.8344285714285714\n",
      "Validation: loss: 0.9684796631336212 , accuracy: 0.77\n",
      "New min loss: 0.9684796631336212\n",
      "189 ) Training: loss: 0.922173349423842 , accuracy: 0.8348571428571429\n",
      "Validation: loss: 0.9683757796883583 , accuracy: 0.77\n",
      "New min loss: 0.9683757796883583\n",
      "190 ) Training: loss: 0.9218482299284502 , accuracy: 0.8348571428571429\n",
      "Validation: loss: 0.9682701304554939 , accuracy: 0.77\n",
      "New min loss: 0.9682701304554939\n",
      "191 ) Training: loss: 0.9215241919864308 , accuracy: 0.835\n",
      "Validation: loss: 0.968164749443531 , accuracy: 0.77\n",
      "New min loss: 0.968164749443531\n",
      "192 ) Training: loss: 0.9211993932723999 , accuracy: 0.8352857142857143\n",
      "Validation: loss: 0.9680569246411324 , accuracy: 0.77\n",
      "New min loss: 0.9680569246411324\n",
      "193 ) Training: loss: 0.920876722986048 , accuracy: 0.8355714285714285\n",
      "Validation: loss: 0.9679525569081306 , accuracy: 0.77\n",
      "New min loss: 0.9679525569081306\n",
      "194 ) Training: loss: 0.9205535986206749 , accuracy: 0.8362857142857143\n",
      "Validation: loss: 0.9678410813212395 , accuracy: 0.77\n",
      "New min loss: 0.9678410813212395\n",
      "195 ) Training: loss: 0.9202283945950595 , accuracy: 0.8364285714285714\n",
      "Validation: loss: 0.9677341431379318 , accuracy: 0.769\n",
      "New min loss: 0.9677341431379318\n",
      "196 ) Training: loss: 0.9199051629413258 , accuracy: 0.8374285714285714\n",
      "Validation: loss: 0.9676255211234093 , accuracy: 0.769\n",
      "New min loss: 0.9676255211234093\n",
      "197 ) Training: loss: 0.9195814934643832 , accuracy: 0.8381428571428572\n",
      "Validation: loss: 0.9675118774175644 , accuracy: 0.769\n",
      "New min loss: 0.9675118774175644\n",
      "198 ) Training: loss: 0.9192574826153842 , accuracy: 0.8381428571428572\n",
      "Validation: loss: 0.9673974439501762 , accuracy: 0.769\n",
      "New min loss: 0.9673974439501762\n",
      "199 ) Training: loss: 0.9189326427199623 , accuracy: 0.8385714285714285\n",
      "Validation: loss: 0.9672806411981583 , accuracy: 0.769\n",
      "New min loss: 0.9672806411981583\n",
      "200 ) Training: loss: 0.9186087760058317 , accuracy: 0.8387142857142857\n",
      "Validation: loss: 0.9671664834022522 , accuracy: 0.769\n",
      "New min loss: 0.9671664834022522\n",
      "201 ) Training: loss: 0.9182875481518832 , accuracy: 0.839\n",
      "Validation: loss: 0.9670501723885536 , accuracy: 0.769\n",
      "New min loss: 0.9670501723885536\n",
      "202 ) Training: loss: 0.9179659301584417 , accuracy: 0.84\n",
      "Validation: loss: 0.9669294357299805 , accuracy: 0.769\n",
      "New min loss: 0.9669294357299805\n",
      "203 ) Training: loss: 0.9176420916210521 , accuracy: 0.8401428571428572\n",
      "Validation: loss: 0.9668139442801476 , accuracy: 0.77\n",
      "New min loss: 0.9668139442801476\n",
      "204 ) Training: loss: 0.9173220190134915 , accuracy: 0.8404285714285714\n",
      "Validation: loss: 0.9666950106620789 , accuracy: 0.77\n",
      "New min loss: 0.9666950106620789\n",
      "205 ) Training: loss: 0.9170029553500089 , accuracy: 0.8405714285714285\n",
      "Validation: loss: 0.9665781036019325 , accuracy: 0.77\n",
      "New min loss: 0.9665781036019325\n",
      "206 ) Training: loss: 0.9166813752867958 , accuracy: 0.8407142857142857\n",
      "Validation: loss: 0.9664619788527489 , accuracy: 0.77\n",
      "New min loss: 0.9664619788527489\n",
      "207 ) Training: loss: 0.9163645668463274 , accuracy: 0.8407142857142857\n",
      "Validation: loss: 0.966347724199295 , accuracy: 0.77\n",
      "New min loss: 0.966347724199295\n",
      "208 ) Training: loss: 0.9160464243455366 , accuracy: 0.8412857142857143\n",
      "Validation: loss: 0.9662361815571785 , accuracy: 0.77\n",
      "New min loss: 0.9662361815571785\n",
      "209 ) Training: loss: 0.9157307635654103 , accuracy: 0.8414285714285714\n",
      "Validation: loss: 0.9661235436797142 , accuracy: 0.77\n",
      "New min loss: 0.9661235436797142\n",
      "210 ) Training: loss: 0.9154149857434359 , accuracy: 0.8415714285714285\n",
      "Validation: loss: 0.9660127237439156 , accuracy: 0.77\n",
      "New min loss: 0.9660127237439156\n",
      "211 ) Training: loss: 0.9150989066470753 , accuracy: 0.8418571428571429\n",
      "Validation: loss: 0.9659056514501572 , accuracy: 0.77\n",
      "New min loss: 0.9659056514501572\n",
      "212 ) Training: loss: 0.9147859985178167 , accuracy: 0.842\n",
      "Validation: loss: 0.9657982662320137 , accuracy: 0.771\n",
      "New min loss: 0.9657982662320137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 ) Training: loss: 0.9144751321185719 , accuracy: 0.8422857142857143\n",
      "Validation: loss: 0.9656887501478195 , accuracy: 0.771\n",
      "New min loss: 0.9656887501478195\n",
      "214 ) Training: loss: 0.9141631776636298 , accuracy: 0.8425714285714285\n",
      "Validation: loss: 0.9655907228589058 , accuracy: 0.771\n",
      "New min loss: 0.9655907228589058\n",
      "215 ) Training: loss: 0.9138513207435608 , accuracy: 0.8427142857142857\n",
      "Validation: loss: 0.9654901102185249 , accuracy: 0.772\n",
      "New min loss: 0.9654901102185249\n",
      "216 ) Training: loss: 0.9135406765070828 , accuracy: 0.843\n",
      "Validation: loss: 0.9653889238834381 , accuracy: 0.772\n",
      "New min loss: 0.9653889238834381\n",
      "217 ) Training: loss: 0.9132289561358365 , accuracy: 0.8435714285714285\n",
      "Validation: loss: 0.9652896672487259 , accuracy: 0.772\n",
      "New min loss: 0.9652896672487259\n",
      "218 ) Training: loss: 0.9129167621785944 , accuracy: 0.844\n",
      "Validation: loss: 0.9651839211583138 , accuracy: 0.772\n",
      "New min loss: 0.9651839211583138\n",
      "219 ) Training: loss: 0.9126063747839495 , accuracy: 0.8441428571428572\n",
      "Validation: loss: 0.9650705382227898 , accuracy: 0.772\n",
      "New min loss: 0.9650705382227898\n",
      "220 ) Training: loss: 0.9122886278412559 , accuracy: 0.8442857142857143\n",
      "Validation: loss: 0.9649718627333641 , accuracy: 0.771\n",
      "New min loss: 0.9649718627333641\n",
      "221 ) Training: loss: 0.9119716134938327 , accuracy: 0.845\n",
      "Validation: loss: 0.964864693582058 , accuracy: 0.771\n",
      "New min loss: 0.964864693582058\n",
      "222 ) Training: loss: 0.9116562323136763 , accuracy: 0.8455714285714285\n",
      "Validation: loss: 0.9647607877850533 , accuracy: 0.771\n",
      "New min loss: 0.9647607877850533\n",
      "223 ) Training: loss: 0.9113396763801574 , accuracy: 0.846\n",
      "Validation: loss: 0.9646520167589188 , accuracy: 0.772\n",
      "New min loss: 0.9646520167589188\n",
      "224 ) Training: loss: 0.9110222090374339 , accuracy: 0.8462857142857143\n",
      "Validation: loss: 0.9645488858222961 , accuracy: 0.772\n",
      "New min loss: 0.9645488858222961\n",
      "225 ) Training: loss: 0.9107070218433033 , accuracy: 0.8472857142857143\n",
      "Validation: loss: 0.9644459933042526 , accuracy: 0.773\n",
      "New min loss: 0.9644459933042526\n",
      "226 ) Training: loss: 0.9103929584676569 , accuracy: 0.8474285714285714\n",
      "Validation: loss: 0.9643414616584778 , accuracy: 0.773\n",
      "New min loss: 0.9643414616584778\n",
      "227 ) Training: loss: 0.9100810343568976 , accuracy: 0.8478571428571429\n",
      "Validation: loss: 0.9642404913902283 , accuracy: 0.776\n",
      "New min loss: 0.9642404913902283\n",
      "228 ) Training: loss: 0.9097700693390586 , accuracy: 0.8481428571428572\n",
      "Validation: loss: 0.9641465172171593 , accuracy: 0.778\n",
      "New min loss: 0.9641465172171593\n",
      "229 ) Training: loss: 0.9094611167907715 , accuracy: 0.8482857142857143\n",
      "Validation: loss: 0.9640553295612335 , accuracy: 0.779\n",
      "New min loss: 0.9640553295612335\n",
      "230 ) Training: loss: 0.9091526042331349 , accuracy: 0.8482857142857143\n",
      "Validation: loss: 0.9639635011553764 , accuracy: 0.781\n",
      "New min loss: 0.9639635011553764\n",
      "231 ) Training: loss: 0.9088425235314803 , accuracy: 0.8484285714285714\n",
      "Validation: loss: 0.9638812392950058 , accuracy: 0.781\n",
      "New min loss: 0.9638812392950058\n",
      "232 ) Training: loss: 0.9085348801179366 , accuracy: 0.8484285714285714\n",
      "Validation: loss: 0.9638010561466217 , accuracy: 0.781\n",
      "New min loss: 0.9638010561466217\n",
      "233 ) Training: loss: 0.9082276626066728 , accuracy: 0.8485714285714285\n",
      "Validation: loss: 0.9637271463871002 , accuracy: 0.781\n",
      "New min loss: 0.9637271463871002\n",
      "234 ) Training: loss: 0.9079218788580461 , accuracy: 0.849\n",
      "Validation: loss: 0.9636556878685951 , accuracy: 0.781\n",
      "New min loss: 0.9636556878685951\n",
      "235 ) Training: loss: 0.9076164906675165 , accuracy: 0.8494285714285714\n",
      "Validation: loss: 0.9635908231139183 , accuracy: 0.781\n",
      "New min loss: 0.9635908231139183\n",
      "236 ) Training: loss: 0.9073075489564375 , accuracy: 0.85\n",
      "Validation: loss: 0.9635340571403503 , accuracy: 0.782\n",
      "New min loss: 0.9635340571403503\n",
      "237 ) Training: loss: 0.9069990775801918 , accuracy: 0.8501428571428571\n",
      "Validation: loss: 0.9634805992245674 , accuracy: 0.782\n",
      "New min loss: 0.9634805992245674\n",
      "238 ) Training: loss: 0.9066912271759727 , accuracy: 0.8508571428571429\n",
      "Validation: loss: 0.9634253233671188 , accuracy: 0.783\n",
      "New min loss: 0.9634253233671188\n",
      "239 ) Training: loss: 0.9063864274458452 , accuracy: 0.8512857142857143\n",
      "Validation: loss: 0.9633752927184105 , accuracy: 0.783\n",
      "New min loss: 0.9633752927184105\n",
      "240 ) Training: loss: 0.9060844508084384 , accuracy: 0.8517142857142858\n",
      "Validation: loss: 0.9633264318108559 , accuracy: 0.783\n",
      "New min loss: 0.9633264318108559\n",
      "241 ) Training: loss: 0.9057866844263944 , accuracy: 0.8518571428571429\n",
      "Validation: loss: 0.9632786586880684 , accuracy: 0.783\n",
      "New min loss: 0.9632786586880684\n",
      "242 ) Training: loss: 0.9054940451275219 , accuracy: 0.8521428571428571\n",
      "Validation: loss: 0.9632270708680153 , accuracy: 0.783\n",
      "New min loss: 0.9632270708680153\n",
      "243 ) Training: loss: 0.9052051555026661 , accuracy: 0.8521428571428571\n",
      "Validation: loss: 0.9631678983569145 , accuracy: 0.783\n",
      "New min loss: 0.9631678983569145\n",
      "244 ) Training: loss: 0.904918640310114 , accuracy: 0.8522857142857143\n",
      "Validation: loss: 0.9631215929985046 , accuracy: 0.784\n",
      "New min loss: 0.9631215929985046\n",
      "245 ) Training: loss: 0.904632183638486 , accuracy: 0.8522857142857143\n",
      "Validation: loss: 0.9630777612328529 , accuracy: 0.784\n",
      "New min loss: 0.9630777612328529\n",
      "246 ) Training: loss: 0.9043469927527688 , accuracy: 0.8525714285714285\n",
      "Validation: loss: 0.9630334004759789 , accuracy: 0.784\n",
      "New min loss: 0.9630334004759789\n",
      "247 ) Training: loss: 0.9040609717369079 , accuracy: 0.8524285714285714\n",
      "Validation: loss: 0.962995283305645 , accuracy: 0.784\n",
      "New min loss: 0.962995283305645\n",
      "248 ) Training: loss: 0.9037763118743897 , accuracy: 0.8525714285714285\n",
      "Validation: loss: 0.9629592075943947 , accuracy: 0.783\n",
      "New min loss: 0.9629592075943947\n",
      "249 ) Training: loss: 0.9034919175234708 , accuracy: 0.8528571428571429\n",
      "Validation: loss: 0.9629268795251846 , accuracy: 0.783\n",
      "New min loss: 0.9629268795251846\n",
      "250 ) Training: loss: 0.9032079165632074 , accuracy: 0.853\n",
      "Validation: loss: 0.9629039838910103 , accuracy: 0.783\n",
      "New min loss: 0.9629039838910103\n",
      "251 ) Training: loss: 0.9029236576773904 , accuracy: 0.8532857142857143\n",
      "Validation: loss: 0.9628865346312523 , accuracy: 0.784\n",
      "New min loss: 0.9628865346312523\n",
      "252 ) Training: loss: 0.9026416702703997 , accuracy: 0.8534285714285714\n",
      "Validation: loss: 0.962878480553627 , accuracy: 0.783\n",
      "New min loss: 0.962878480553627\n",
      "253 ) Training: loss: 0.9023596286773682 , accuracy: 0.8537142857142858\n",
      "Validation: loss: 0.96287040412426 , accuracy: 0.782\n",
      "New min loss: 0.96287040412426\n",
      "254 ) Training: loss: 0.9020762898705222 , accuracy: 0.8538571428571429\n",
      "Validation: loss: 0.9628652408719063 , accuracy: 0.782\n",
      "New min loss: 0.9628652408719063\n",
      "255 ) Training: loss: 0.9017936002124439 , accuracy: 0.8541428571428571\n",
      "Validation: loss: 0.9628606587648392 , accuracy: 0.782\n",
      "New min loss: 0.9628606587648392\n",
      "256 ) Training: loss: 0.9015130682425065 , accuracy: 0.8541428571428571\n",
      "Validation: loss: 0.962852917611599 , accuracy: 0.782\n",
      "New min loss: 0.962852917611599\n",
      "257 ) Training: loss: 0.901233084635301 , accuracy: 0.8545714285714285\n",
      "Validation: loss: 0.9628536701202393 , accuracy: 0.782\n",
      "258 ) Training: loss: 0.9009543332186613 , accuracy: 0.8545714285714285\n",
      "Validation: loss: 0.9628574624657631 , accuracy: 0.782\n",
      "259 ) Training: loss: 0.9006751851602034 , accuracy: 0.8545714285714285\n",
      "Validation: loss: 0.962853766977787 , accuracy: 0.78\n",
      "260 ) Training: loss: 0.9003972736271945 , accuracy: 0.8551428571428571\n",
      "Validation: loss: 0.962852954864502 , accuracy: 0.779\n",
      "261 ) Training: loss: 0.9001167221502824 , accuracy: 0.8555714285714285\n",
      "Validation: loss: 0.9628502056002617 , accuracy: 0.778\n",
      "New min loss: 0.9628502056002617\n",
      "262 ) Training: loss: 0.8998352885246277 , accuracy: 0.8565714285714285\n",
      "Validation: loss: 0.962849423289299 , accuracy: 0.778\n",
      "New min loss: 0.962849423289299\n",
      "263 ) Training: loss: 0.8995547327128324 , accuracy: 0.8571428571428571\n",
      "Validation: loss: 0.9628499001264572 , accuracy: 0.779\n",
      "264 ) Training: loss: 0.8992761741984975 , accuracy: 0.8575714285714285\n",
      "Validation: loss: 0.962842620909214 , accuracy: 0.779\n",
      "New min loss: 0.962842620909214\n",
      "265 ) Training: loss: 0.8990009448745034 , accuracy: 0.8577142857142858\n",
      "Validation: loss: 0.962830625474453 , accuracy: 0.779\n",
      "New min loss: 0.962830625474453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 ) Training: loss: 0.8987254446203058 , accuracy: 0.8575714285714285\n",
      "Validation: loss: 0.9628125131130219 , accuracy: 0.778\n",
      "New min loss: 0.9628125131130219\n",
      "267 ) Training: loss: 0.8984558170491999 , accuracy: 0.8578571428571429\n",
      "Validation: loss: 0.9627813175320625 , accuracy: 0.778\n",
      "New min loss: 0.9627813175320625\n",
      "268 ) Training: loss: 0.8981888543475758 , accuracy: 0.8582857142857143\n",
      "Validation: loss: 0.9627517387270927 , accuracy: 0.778\n",
      "New min loss: 0.9627517387270927\n",
      "269 ) Training: loss: 0.8979250929572365 , accuracy: 0.8587142857142858\n",
      "Validation: loss: 0.962711326777935 , accuracy: 0.778\n",
      "New min loss: 0.962711326777935\n",
      "270 ) Training: loss: 0.897661665352908 , accuracy: 0.8588571428571429\n",
      "Validation: loss: 0.9626639112830162 , accuracy: 0.777\n",
      "New min loss: 0.9626639112830162\n",
      "271 ) Training: loss: 0.8973999337716536 , accuracy: 0.859\n",
      "Validation: loss: 0.9626071229577065 , accuracy: 0.778\n",
      "New min loss: 0.9626071229577065\n",
      "272 ) Training: loss: 0.897140028259971 , accuracy: 0.8594285714285714\n",
      "Validation: loss: 0.9625466391444206 , accuracy: 0.778\n",
      "New min loss: 0.9625466391444206\n",
      "273 ) Training: loss: 0.8968806353482333 , accuracy: 0.8601428571428571\n",
      "Validation: loss: 0.9624821469187737 , accuracy: 0.778\n",
      "New min loss: 0.9624821469187737\n",
      "274 ) Training: loss: 0.8966221029108221 , accuracy: 0.8602857142857143\n",
      "Validation: loss: 0.9624105989933014 , accuracy: 0.778\n",
      "New min loss: 0.9624105989933014\n",
      "275 ) Training: loss: 0.896366163817319 , accuracy: 0.8605714285714285\n",
      "Validation: loss: 0.9623512923717499 , accuracy: 0.778\n",
      "New min loss: 0.9623512923717499\n",
      "276 ) Training: loss: 0.8961094617843628 , accuracy: 0.8605714285714285\n",
      "Validation: loss: 0.9622990787029266 , accuracy: 0.78\n",
      "New min loss: 0.9622990787029266\n",
      "277 ) Training: loss: 0.89585327018391 , accuracy: 0.8608571428571429\n",
      "Validation: loss: 0.9622373580932617 , accuracy: 0.78\n",
      "New min loss: 0.9622373580932617\n",
      "278 ) Training: loss: 0.8955988407135009 , accuracy: 0.8612857142857143\n",
      "Validation: loss: 0.9621783569455147 , accuracy: 0.779\n",
      "New min loss: 0.9621783569455147\n",
      "279 ) Training: loss: 0.8953437219966541 , accuracy: 0.8614285714285714\n",
      "Validation: loss: 0.9621178433299065 , accuracy: 0.779\n",
      "New min loss: 0.9621178433299065\n",
      "280 ) Training: loss: 0.8950891386378895 , accuracy: 0.8617142857142858\n",
      "Validation: loss: 0.9620669335126877 , accuracy: 0.78\n",
      "New min loss: 0.9620669335126877\n",
      "281 ) Training: loss: 0.8948361353440718 , accuracy: 0.8618571428571429\n",
      "Validation: loss: 0.9620178565382957 , accuracy: 0.779\n",
      "New min loss: 0.9620178565382957\n",
      "282 ) Training: loss: 0.8945859573104165 , accuracy: 0.862\n",
      "Validation: loss: 0.9619777575135231 , accuracy: 0.781\n",
      "New min loss: 0.9619777575135231\n",
      "283 ) Training: loss: 0.894336525960402 , accuracy: 0.8622857142857143\n",
      "Validation: loss: 0.9619421884417534 , accuracy: 0.781\n",
      "New min loss: 0.9619421884417534\n",
      "284 ) Training: loss: 0.8940889423543756 , accuracy: 0.8627142857142858\n",
      "Validation: loss: 0.9619154334068298 , accuracy: 0.779\n",
      "New min loss: 0.9619154334068298\n",
      "285 ) Training: loss: 0.893843056938865 , accuracy: 0.8627142857142858\n",
      "Validation: loss: 0.9618899300694466 , accuracy: 0.779\n",
      "New min loss: 0.9618899300694466\n",
      "286 ) Training: loss: 0.8935962969606573 , accuracy: 0.8627142857142858\n",
      "Validation: loss: 0.9618556946516037 , accuracy: 0.779\n",
      "New min loss: 0.9618556946516037\n",
      "287 ) Training: loss: 0.8933517672798851 , accuracy: 0.8628571428571429\n",
      "Validation: loss: 0.9618326425552368 , accuracy: 0.78\n",
      "New min loss: 0.9618326425552368\n",
      "288 ) Training: loss: 0.8931047450412404 , accuracy: 0.8634285714285714\n",
      "Validation: loss: 0.9617957696318626 , accuracy: 0.778\n",
      "New min loss: 0.9617957696318626\n",
      "289 ) Training: loss: 0.8928554112260992 , accuracy: 0.8635714285714285\n",
      "Validation: loss: 0.9617541506886482 , accuracy: 0.777\n",
      "New min loss: 0.9617541506886482\n",
      "290 ) Training: loss: 0.8926021738485856 , accuracy: 0.8638571428571429\n",
      "Validation: loss: 0.9617016166448593 , accuracy: 0.778\n",
      "New min loss: 0.9617016166448593\n",
      "291 ) Training: loss: 0.8923480965874412 , accuracy: 0.8641428571428571\n",
      "Validation: loss: 0.9616458788514137 , accuracy: 0.777\n",
      "New min loss: 0.9616458788514137\n",
      "292 ) Training: loss: 0.8920927307822487 , accuracy: 0.8644285714285714\n",
      "Validation: loss: 0.96158067882061 , accuracy: 0.777\n",
      "New min loss: 0.96158067882061\n",
      "293 ) Training: loss: 0.8918387879024853 , accuracy: 0.8647142857142858\n",
      "Validation: loss: 0.961507111787796 , accuracy: 0.777\n",
      "New min loss: 0.961507111787796\n",
      "294 ) Training: loss: 0.8915840983390808 , accuracy: 0.8647142857142858\n",
      "Validation: loss: 0.9614354148507118 , accuracy: 0.775\n",
      "New min loss: 0.9614354148507118\n",
      "295 ) Training: loss: 0.8913294044407931 , accuracy: 0.8647142857142858\n",
      "Validation: loss: 0.9613634869456291 , accuracy: 0.775\n",
      "New min loss: 0.9613634869456291\n",
      "296 ) Training: loss: 0.8910733147100969 , accuracy: 0.8654285714285714\n",
      "Validation: loss: 0.9612946063280106 , accuracy: 0.775\n",
      "New min loss: 0.9612946063280106\n",
      "297 ) Training: loss: 0.8908185807141391 , accuracy: 0.8658571428571429\n",
      "Validation: loss: 0.9612227231264114 , accuracy: 0.776\n",
      "New min loss: 0.9612227231264114\n",
      "298 ) Training: loss: 0.890565317327326 , accuracy: 0.866\n",
      "Validation: loss: 0.9611537456512451 , accuracy: 0.779\n",
      "New min loss: 0.9611537456512451\n",
      "299 ) Training: loss: 0.8903091398152438 , accuracy: 0.8661428571428571\n",
      "Validation: loss: 0.9610901102423668 , accuracy: 0.779\n",
      "New min loss: 0.9610901102423668\n",
      "300 ) Training: loss: 0.8900513475591486 , accuracy: 0.8664285714285714\n",
      "Validation: loss: 0.9610196053981781 , accuracy: 0.779\n",
      "New min loss: 0.9610196053981781\n"
     ]
    }
   ],
   "source": [
    "# HINT: note that your training time should not take more than 2 hours.\n",
    "\n",
    "max_epoch = 300\n",
    "train_batch = 128\n",
    "test_batch = 128\n",
    "learning_rate = 1e-04\n",
    "  \n",
    "best_path = \"best_cnn_adam.pth\"\n",
    "# Create train dataset loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch)\n",
    "# Create validation dataset loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=train_batch)\n",
    "# Create test dataset loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch)\n",
    "# initialize your network\n",
    "model = ConvNet()\n",
    "device = torch.device(dev)\n",
    "model = model.to(device)\n",
    "# define your loss function\n",
    "criterion = nn.CrossEntropyLoss()    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-04) # you can play with  weight_decay as well\n",
    "# start training\n",
    "# for each epoch calculate validation performance\n",
    "# save best model according to validation performance\n",
    "tr_losses=[]\n",
    "tr_accuracies=[]\n",
    "val_losses=[]\n",
    "val_accuracies=[]\n",
    "i = 1\n",
    "min_loss = np.inf\n",
    "for epoch in range(max_epoch):\n",
    "    model=model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    correct = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()   \n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        gt = y_batch.data.max(1, keepdim=True)[1]\n",
    "        #print(\"pred:\", pred, \", gt:\", gt)\n",
    "        correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    accuracy = (correct.item()/len(train_loader.dataset))\n",
    "    tr_accuracies.append(accuracy)\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    tr_losses.append(avg_loss)\n",
    "    print(i,\") Training: loss:\", avg_loss, \", accuracy:\", accuracy)\n",
    "    i += 1\n",
    "\n",
    "    #    Validation\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    correct = 0\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch = batch[0].to(device)\n",
    "            y_batch = batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "            gt = y_batch.data.max(1, keepdim=True)[1]\n",
    "            #print(\"pred:\", pred, \", gt:\", gt)\n",
    "            correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "            epoch_losses.append(loss.item())\n",
    "        accuracy = (correct.item()/len(val_loader.dataset))\n",
    "        val_accuracies.append(accuracy)    \n",
    "        avg_loss = np.mean(epoch_losses)    \n",
    "        val_losses.append(avg_loss)\n",
    "        print(\"Validation: loss:\", avg_loss, \", accuracy:\", accuracy)\n",
    "        if avg_loss < min_loss:\n",
    "            torch.save(model, best_path)\n",
    "            min_loss = avg_loss\n",
    "            print(\"New min loss:\", min_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses vs epoch \n",
    "plt.figure(3)  \n",
    "plt.plot(np.arange(1,301), tr_losses, np.arange(1,301), val_losses)\n",
    "plt.title(\"Loss vs Epoch with Adam Optimizer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "# plot losses vs epoch \n",
    "plt.figure(4)  \n",
    "plt.plot(np.arange(1,301), tr_accuracies, np.arange(1,301), val_accuracies)\n",
    "plt.title(\"Accuracy vs Epoch with Adam Optimizer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iozVeXZAXiH"
   },
   "source": [
    "####Test with ADAM [10 pts.]\n",
    "\n",
    "Report the following for your best model on your test set which has not been seen by the model yet.\n",
    "1. A heatmap for confusion matrix\n",
    "2. Accuracy\n",
    "3. Macro Precision\n",
    "4. Macro Recall\n",
    "5. F1 Score\n",
    "\n",
    "Then, discuss figures that you have plotted in the previous section, your test results and algorithm complexity with maximum 200 words. Compare two **optimizers**. Which one is more preferable? Why?\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_t27l0hN9FqS",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: 0.9627442769706249 \n",
      "Mean Acc: 0.7825 \n",
      "Mean Macro Precision: 0.7791089425496789 \n",
      "Mean Macro Recall: 0.7792082659947732 \n",
      "Mean Macro F1 Score: 0.7791586011069056\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test CNN\n",
    "# load best model\n",
    "best_path = \"best_cnn_adam.pth\"\n",
    "model = torch.load(best_path).to(device)\n",
    "\n",
    "#evaluate on test set\n",
    "model = model.eval()\n",
    "predictions = []\n",
    "ground_truths=[]\n",
    "losses = []\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        losses.append(loss.item())\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1].cpu()\n",
    "        gt = y_batch.data.max(1, keepdim=True)[1].cpu()\n",
    "        correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "        pred = pred.reshape(len(pred))\n",
    "        gt = gt.reshape(len(gt))\n",
    "        predictions = np.concatenate((predictions, pred))\n",
    "        ground_truths = np.concatenate((ground_truths, gt))\n",
    "avg_loss = np.mean(losses)    \n",
    "accuracy = (correct.item()/len(test_loader.dataset))\n",
    "conf_matrix = confusion_matrix(predictions, ground_truths)  \n",
    "#   calculate precision\n",
    "p_0 = conf_matrix[0,0]/np.sum(conf_matrix[0,:])\n",
    "p_1 = conf_matrix[1,1]/np.sum(conf_matrix[1,:])\n",
    "p_2 = conf_matrix[2,2]/np.sum(conf_matrix[2,:])\n",
    "p_3 = conf_matrix[3,3]/np.sum(conf_matrix[3,:])\n",
    "mean_precision = (p_0 + p_1 + p_2 + p_3)/4\n",
    "#   calculate recall\n",
    "r_0 = conf_matrix[0,0]/np.sum(conf_matrix[:,0])\n",
    "r_1 = conf_matrix[1,1]/np.sum(conf_matrix[:,1])\n",
    "r_2 = conf_matrix[2,2]/np.sum(conf_matrix[:,2])\n",
    "r_3 = conf_matrix[3,3]/np.sum(conf_matrix[:,3])\n",
    "mean_recall = (r_0 + r_1 + r_2 + r_3)/4\n",
    "#   calculate F1 score\n",
    "f1 = (2*mean_precision*mean_recall)/(mean_precision+mean_recall)\n",
    "\n",
    "# print metrics\n",
    "print(\"Mean Loss:\", avg_loss, \"\\nMean Acc:\", accuracy, \"\\nMean Macro Precision:\", mean_precision, \"\\nMean Macro Recall:\", mean_recall, \"\\nMean Macro F1 Score:\", f1) \n",
    "\n",
    "# plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_matrix)\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(4))\n",
    "ax.set_yticks(np.arange(4))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Adam optimizer produced a better result than SGD. The result is better in terms of training accuracy and also in terms of the training and validation accuracy plots, which have more fluctuations for SGD and less for Adam. For learning rates less than 1e-02, SGD had problem with converging and the accuracy was poor. However, Adam worked quite well with the learning rate 1e-02. The algorithm complexity is linearly dependent to (number_of_epochs * dataset_size) since it goes over the entire dataset in each epoch. In general, the results show that Adam is more preferable than SGD due to its better accuracy and more stable behavior. The model with Adam also converges more quickly, which is another advantage of Adam over SGD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUsvHO7JUvK8"
   },
   "source": [
    "###Transfer Learning [25 pts.]\n",
    "\n",
    "Instead of training CNNs from scratch, you can use pretrained models and apply them to your task. Transfer learning is a machine learning technique where you can reuse a pretrained machine learning model as a starting point for your own task. In this question, you will experiment with it and try to understand why it is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SdoJEXuUvK9"
   },
   "source": [
    "####Training with Transfer Learning [15 pts.]\n",
    "\n",
    "Get pretrained ResNet18 model from torchvision.models and finetune your model up to 20 epochs with properly processed inputs, i.e. call your \"get_dataset\". This time use transfer learning. Tune your learning rate, weight decay. Save your best model as \"best_cnn_transfer.pth\". The best model should be selected based on validation dataset. You could use any measurement and/or metric to decide on the best model for each network. However, you must explain your reasoning in your choice.\n",
    "\n",
    "During training, you need to plot two figures:\n",
    "1. training loss and validation loss vs. epoch\n",
    "2. training accuracy and validation accuracy vs. epoch <br>\n",
    "\n",
    "Name your axes and plots properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "q53czB57UvK9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) Training: loss: 0.7109111401167783 , accuracy: 0.7268571428571429\n",
      "Validation: loss: 0.43682392686605453 , accuracy: 0.849\n",
      "New min loss: 0.43682392686605453\n",
      "2 ) Training: loss: 0.3111611420458013 , accuracy: 0.8938571428571429\n",
      "Validation: loss: 0.35846032947301865 , accuracy: 0.872\n",
      "New min loss: 0.35846032947301865\n",
      "3 ) Training: loss: 0.19330512596802277 , accuracy: 0.9412857142857143\n",
      "Validation: loss: 0.33855678141117096 , accuracy: 0.888\n",
      "New min loss: 0.33855678141117096\n",
      "4 ) Training: loss: 0.12411133484406904 , accuracy: 0.9695714285714285\n",
      "Validation: loss: 0.33521027863025665 , accuracy: 0.891\n",
      "New min loss: 0.33521027863025665\n",
      "5 ) Training: loss: 0.08125197867100889 , accuracy: 0.9861428571428571\n",
      "Validation: loss: 0.3402869217097759 , accuracy: 0.891\n",
      "6 ) Training: loss: 0.05465534752742811 , accuracy: 0.9931428571428571\n",
      "Validation: loss: 0.348627295345068 , accuracy: 0.891\n",
      "7 ) Training: loss: 0.03836322186345404 , accuracy: 0.9964285714285714\n",
      "Validation: loss: 0.3555653654038906 , accuracy: 0.892\n",
      "8 ) Training: loss: 0.028123994916677476 , accuracy: 0.9975714285714286\n",
      "Validation: loss: 0.3604774922132492 , accuracy: 0.895\n",
      "9 ) Training: loss: 0.021429661085659808 , accuracy: 0.999\n",
      "Validation: loss: 0.365538127720356 , accuracy: 0.893\n",
      "10 ) Training: loss: 0.01688090469688177 , accuracy: 0.9992857142857143\n",
      "Validation: loss: 0.3696111887693405 , accuracy: 0.892\n",
      "11 ) Training: loss: 0.013689493701200593 , accuracy: 0.9995714285714286\n",
      "Validation: loss: 0.3731581047177315 , accuracy: 0.893\n",
      "12 ) Training: loss: 0.011408466422422365 , accuracy: 0.9997142857142857\n",
      "Validation: loss: 0.37691516801714897 , accuracy: 0.89\n",
      "13 ) Training: loss: 0.009715245393189516 , accuracy: 0.9998571428571429\n",
      "Validation: loss: 0.38091276213526726 , accuracy: 0.891\n",
      "14 ) Training: loss: 0.008384576795453375 , accuracy: 0.9998571428571429\n",
      "Validation: loss: 0.3849990703165531 , accuracy: 0.892\n",
      "15 ) Training: loss: 0.007346190927042202 , accuracy: 0.9998571428571429\n",
      "Validation: loss: 0.38921212404966354 , accuracy: 0.893\n",
      "16 ) Training: loss: 0.006506280186162753 , accuracy: 0.9998571428571429\n",
      "Validation: loss: 0.3933034799993038 , accuracy: 0.893\n",
      "17 ) Training: loss: 0.005829209101979028 , accuracy: 0.9998571428571429\n",
      "Validation: loss: 0.39696672186255455 , accuracy: 0.893\n",
      "18 ) Training: loss: 0.005249566051431677 , accuracy: 1.0\n",
      "Validation: loss: 0.40039875730872154 , accuracy: 0.894\n",
      "19 ) Training: loss: 0.004762127648361704 , accuracy: 1.0\n",
      "Validation: loss: 0.40362072736024857 , accuracy: 0.893\n",
      "20 ) Training: loss: 0.004335493276911703 , accuracy: 1.0\n",
      "Validation: loss: 0.4066713862121105 , accuracy: 0.893\n"
     ]
    }
   ],
   "source": [
    "# HINT: note that your training time should not take more than 2 hours.\n",
    "best_path = \"best_cnn_transfer.pth\"\n",
    "# TODO:\n",
    "# Pick your hyper parameters\n",
    "max_epoch = 20\n",
    "train_batch = 128\n",
    "test_batch = 128 \n",
    "learning_rate = 1e-02 # try learning rate from the interval [1e-1, 1e-4]\n",
    "\n",
    "#use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# Create train dataset loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch)\n",
    "# Create validation dataset loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=train_batch)\n",
    "# Create test dataset loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch)\n",
    "\n",
    "# initialize your network\n",
    "device = torch.device(dev)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(512, 4)\n",
    "model = model.to(device)\n",
    "\n",
    "# define your loss function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 5e-04) # you can play with momentum and weight_decay parameters as well\n",
    "    \n",
    "tr_losses=[]\n",
    "tr_accuracies=[]\n",
    "val_losses=[]\n",
    "val_accuracies=[]\n",
    "i = 1\n",
    "min_loss = np.inf\n",
    "for epoch in range(max_epoch):\n",
    "    model=model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    correct = 0\n",
    "    for batch in train_loader:\n",
    "        x_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()   \n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        gt = y_batch.data.max(1, keepdim=True)[1]\n",
    "        #print(\"pred:\", pred, \", gt:\", gt)\n",
    "        correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    accuracy = (correct.item()/len(train_loader.dataset))\n",
    "    tr_accuracies.append(accuracy)\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    tr_losses.append(avg_loss)\n",
    "    print(i,\") Training: loss:\", avg_loss, \", accuracy:\", accuracy)\n",
    "    i += 1\n",
    "\n",
    "    #    Validation\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    correct = 0\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch = batch[0].to(device)\n",
    "            y_batch = batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "            gt = y_batch.data.max(1, keepdim=True)[1]\n",
    "            #print(\"pred:\", pred, \", gt:\", gt)\n",
    "            correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "            epoch_losses.append(loss.item())\n",
    "        accuracy = (correct.item()/len(val_loader.dataset))\n",
    "        val_accuracies.append(accuracy)    \n",
    "        avg_loss = np.mean(epoch_losses)    \n",
    "        val_losses.append(avg_loss)\n",
    "        print(\"Validation: loss:\", avg_loss, \", accuracy:\", accuracy)\n",
    "        if avg_loss < min_loss:\n",
    "            torch.save(model, best_path)\n",
    "            min_loss = avg_loss\n",
    "            print(\"New min loss:\", min_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses vs epoch \n",
    "plt.figure(5)  \n",
    "plt.plot(np.arange(1,21), tr_losses, np.arange(1,21), val_losses)\n",
    "plt.title(\"Loss vs Epoch with Transfer Learning\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "# plot losses vs epoch \n",
    "plt.figure(6)  \n",
    "plt.plot(np.arange(1,21), tr_accuracies, np.arange(1,21), val_accuracies)\n",
    "plt.title(\"Accuracy vs Epoch with Transfer Learning\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu9HNrNMUvK_"
   },
   "source": [
    "####Test for Transfer Learning [10 pts.]\n",
    "\n",
    "Report the following for your best model on your test set which has not been seen by the model yet.\n",
    "1. A heatmap for confusion matrix\n",
    "2. Accuracy\n",
    "3. Macro Precision\n",
    "4. Macro Recall\n",
    "5. F1 Score\n",
    "\n",
    "Then, discuss figures that you have plotted in the previous section, your test results and algorithm complexity with maximum 200 words. Explain the advantages of using transfer learning. Is it better to reuse a pretrained model instead of training a model from scratch? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2mUn9CdYUvLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: 0.33951204270124435 \n",
      "Mean Acc: 0.8855 \n",
      "Mean Macro Precision: 0.8845995156762574 \n",
      "Mean Macro Recall: 0.8837439154773581 \n",
      "Mean Macro F1 Score: 0.8841715085888191\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test CNN\n",
    "# load best model\n",
    "best_path = \"best_cnn_transfer.pth\"\n",
    "model = torch.load(best_path).to(device)\n",
    "\n",
    "#evaluate on test set\n",
    "model = model.eval()\n",
    "predictions = []\n",
    "ground_truths=[]\n",
    "losses = []\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        losses.append(loss.item())\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1].cpu()\n",
    "        gt = y_batch.data.max(1, keepdim=True)[1].cpu()\n",
    "        correct += pred.eq(gt.data.view_as(pred)).cpu().sum()\n",
    "        pred = pred.reshape(len(pred))\n",
    "        gt = gt.reshape(len(gt))\n",
    "        predictions = np.concatenate((predictions, pred))\n",
    "        ground_truths = np.concatenate((ground_truths, gt))\n",
    "avg_loss = np.mean(losses)    \n",
    "accuracy = (correct.item()/len(test_loader.dataset))\n",
    "conf_matrix = confusion_matrix(predictions, ground_truths)  \n",
    "#   calculate precision\n",
    "p_0 = conf_matrix[0,0]/np.sum(conf_matrix[0,:])\n",
    "p_1 = conf_matrix[1,1]/np.sum(conf_matrix[1,:])\n",
    "p_2 = conf_matrix[2,2]/np.sum(conf_matrix[2,:])\n",
    "p_3 = conf_matrix[3,3]/np.sum(conf_matrix[3,:])\n",
    "mean_precision = (p_0 + p_1 + p_2 + p_3)/4\n",
    "#   calculate recall\n",
    "r_0 = conf_matrix[0,0]/np.sum(conf_matrix[:,0])\n",
    "r_1 = conf_matrix[1,1]/np.sum(conf_matrix[:,1])\n",
    "r_2 = conf_matrix[2,2]/np.sum(conf_matrix[:,2])\n",
    "r_3 = conf_matrix[3,3]/np.sum(conf_matrix[:,3])\n",
    "mean_recall = (r_0 + r_1 + r_2 + r_3)/4\n",
    "#   calculate F1 score\n",
    "f1 = (2*mean_precision*mean_recall)/(mean_precision+mean_recall)\n",
    "\n",
    "# print metrics\n",
    "print(\"Mean Loss:\", avg_loss, \"\\nMean Acc:\", accuracy, \"\\nMean Macro Precision:\", mean_precision, \"\\nMean Macro Recall:\", mean_recall, \"\\nMean Macro F1 Score:\", f1) \n",
    "\n",
    "# plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_matrix)\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(4))\n",
    "ax.set_yticks(np.arange(4))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous algorithms, the algorithm is linearly dependent on (number_of_epochs * dataset_size) since it goes over the entire dataset in each epoch. The pretrained model produced a better accuracy compared to the models built from scratch, even though it uses much less epochs compared to them. The accuracy was around 0.74-0.78 for the other models and around 0.89 for the pretrained model. The pretrained model also produced a smoother graph, especially compared to the model with SGD which had fluctuations. The loss is also much less for this model compared to the previous models. The model converged more quickly because its weights were already optimized, which is an advantage of pretrained model over the other models that were built from scratch."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cs464_fall21_hw3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
